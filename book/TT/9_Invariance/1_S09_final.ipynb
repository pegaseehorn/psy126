{"cells":[{"cell_type":"markdown","metadata":{"id":"0dtwBaFyRwzF"},"source":["# Testing rpy2: Princals\n","\n","We first start with setting up the environment and install the required R and Python packages:"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"dUHdGXyHlg7p","outputId":"bbc21598-85c7-49cb-cbdc-5b29b68becea","executionInfo":{"status":"ok","timestamp":1741898937406,"user_tz":-60,"elapsed":635432,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","R version 4.4.3 (2025-02-28) -- \"Trophy Case\"\n","Copyright (C) 2025 The R Foundation for Statistical Computing\n","Platform: x86_64-pc-linux-gnu\n","\n","R is free software and comes with ABSOLUTELY NO WARRANTY.\n","You are welcome to redistribute it under certain conditions.\n","Type 'license()' or 'licence()' for distribution details.\n","\n","  Natural language support but running in an English locale\n","\n","R is a collaborative project with many contributors.\n","Type 'contributors()' for more information and\n","'citation()' on how to cite R or R packages in publications.\n","\n","Type 'demo()' for some demos, 'help()' for on-line help, or\n","'help.start()' for an HTML browser interface to help.\n","Type 'q()' to quit R.\n","\n","> install.packages(c('lavaan', 'semTools', 'MPsychoR', 'lordif', 'Hmisc'), repos='https://cran.uni-muenster.de', quiet=TRUE)\n","also installing the dependencies ‘audio’, ‘globals’, ‘listenv’, ‘R.oo’, ‘R.methodsS3’, ‘zoo’, ‘permute’, ‘parallelly’, ‘beepr’, ‘RPushbullet’, ‘future’, ‘future.apply’, ‘progressr’, ‘R.utils’, ‘MatrixModels’, ‘mvtnorm’, ‘TH.data’, ‘sandwich’, ‘GPArotation’, ‘vegan’, ‘Deriv’, ‘pbapply’, ‘dcurver’, ‘SimDesign’, ‘RcppArmadillo’, ‘quantreg’, ‘SparseM’, ‘polspline’, ‘multcomp’, ‘iterators’, ‘snow’, ‘checkmate’, ‘mnormt’, ‘pbivnorm’, ‘numDeriv’, ‘quadprog’, ‘mirt’, ‘rms’, ‘doSNOW’, ‘foreach’, ‘gridExtra’, ‘htmlTable’, ‘viridis’, ‘Formula’\n","\n","> \n","> \n","Requirement already satisfied: rpy2==3.5.17 in /usr/local/lib/python3.11/dist-packages (3.5.17)\n","Requirement already satisfied: cffi>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from rpy2==3.5.17) (1.17.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from rpy2==3.5.17) (3.1.6)\n","Requirement already satisfied: tzlocal in /usr/local/lib/python3.11/dist-packages (from rpy2==3.5.17) (5.3.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.15.1->rpy2==3.5.17) (2.22)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->rpy2==3.5.17) (3.0.2)\n"]}],"source":["!R -e \"install.packages(c('lavaan', 'semTools', 'MPsychoR', 'lordif', 'Hmisc'), repos='https://cran.uni-muenster.de', quiet=TRUE)\"\n","!pip install rpy2==3.5.17"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11164,"status":"ok","timestamp":1741899968424,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"},"user_tz":-60},"id":"E57mXg5eZssL","outputId":"8fd66f68-9b43-4e4b-8c37-8573d6005039"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["rpy2.robjects.packages.Package as a <module 'Hmisc'>"]},"metadata":{},"execution_count":2}],"source":["# General imports\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Rpy2 imports\n","from rpy2 import robjects as ro\n","from rpy2.robjects import pandas2ri, numpy2ri\n","from rpy2.robjects.packages import importr\n","\n","# Automatic conversion of arrays and dataframes\n","pandas2ri.activate()\n","numpy2ri.activate()\n","\n","# Set random seed for reproducibility\n","ro.r('set.seed(123)')\n","\n","# Ipython extenrsion for magix plotting\n","%load_ext rpy2.ipython\n","\n","# R imports\n","importr('base')\n","importr('lavaan')\n","importr('semTools')\n","importr('MPsychoR')\n","importr('lordif')\n","importr('Hmisc')\n","\n","\n"]},{"cell_type":"markdown","source":["## 1. Measurement invariance across groups for quantitative item responses\n","\n","Measurement invariance means that we measure the same psychological construct across groups and time (see lectures 8 & 9 for examples). In the following RMD we will look at how we can assess measurement invariance across...\n","\n","* **groups** for **quantitative** item responses\n","* **groups** for **qualitative** item responses\n","* **time** for **quantitative** responses  \n","\n","The four most important measurement invariance structures are the following:\n","\n","* **Configural invariance:** same factor structure but unrestricted loadings and intercepts across groups.\n","* **Metric invariance:** the factor structure and the loadings are constrained to be equal across groups; the intercepts are free. (In the book this is referred to as *Weak invariance*)\n","* **Scale invariance:** the factor structure, the loadings and the indicator intercepts are restricted to be equal across groups. (In the book this is referred to as *Strong invariance*)\n","* **Strict invariance:** the factor structure, the loadings, the indicator intercepts and the reliabilities are restricted to be equal across groups.\n","\n","Note. In the book there's is also a model in which, in addition to the indicator intercepts, the means of the latent\n","variables are restricted to be equal as well, however we won't cover this here.  \n","\n","Try to load and inspect the dataset. It's called `Bergh`.\n","\n","### Load, prepare and inspect the dataset"],"metadata":{"id":"HmZzRlPHasZA"}},{"cell_type":"code","source":["ro.r('data(\"Bergh\")')\n","# Convert to Python\n","Bergh = pandas2ri.rpy2py(ro.globalenv['Bergh'])\n","Bergh.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"Ua_6sGutatD6","executionInfo":{"status":"ok","timestamp":1741899994102,"user_tz":-60,"elapsed":121,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"2af8a503-a113-43bb-c160-719b67b58d09"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["         EP     SP   HP        DP      A1        A2        A3      O1  \\\n","1  2.666667  3.125  1.4  2.818182  3.4375  3.600000  3.352941  2.8750   \n","2  2.666667  3.250  1.4  2.545455  2.3125  2.666667  3.117647  4.4375   \n","3  1.000000  1.625  2.7  2.000000  3.5625  4.600000  3.941176  4.2500   \n","4  2.666667  2.750  1.8  2.818182  2.7500  3.200000  3.352941  2.8750   \n","5  2.888889  3.250  2.7  3.000000  3.2500  4.200000  3.764706  3.9375   \n","\n","         O2        O3  gender  \n","1  3.400000  3.176471       1  \n","2  3.866667  4.470588       1  \n","3  3.666667  3.705882       1  \n","4  3.400000  3.117647       1  \n","5  4.400000  4.294118       1  "],"text/html":["\n","  <div id=\"df-ecdf16e0-8890-49c5-bc3d-997206742f66\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>EP</th>\n","      <th>SP</th>\n","      <th>HP</th>\n","      <th>DP</th>\n","      <th>A1</th>\n","      <th>A2</th>\n","      <th>A3</th>\n","      <th>O1</th>\n","      <th>O2</th>\n","      <th>O3</th>\n","      <th>gender</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>2.666667</td>\n","      <td>3.125</td>\n","      <td>1.4</td>\n","      <td>2.818182</td>\n","      <td>3.4375</td>\n","      <td>3.600000</td>\n","      <td>3.352941</td>\n","      <td>2.8750</td>\n","      <td>3.400000</td>\n","      <td>3.176471</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2.666667</td>\n","      <td>3.250</td>\n","      <td>1.4</td>\n","      <td>2.545455</td>\n","      <td>2.3125</td>\n","      <td>2.666667</td>\n","      <td>3.117647</td>\n","      <td>4.4375</td>\n","      <td>3.866667</td>\n","      <td>4.470588</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.000000</td>\n","      <td>1.625</td>\n","      <td>2.7</td>\n","      <td>2.000000</td>\n","      <td>3.5625</td>\n","      <td>4.600000</td>\n","      <td>3.941176</td>\n","      <td>4.2500</td>\n","      <td>3.666667</td>\n","      <td>3.705882</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2.666667</td>\n","      <td>2.750</td>\n","      <td>1.8</td>\n","      <td>2.818182</td>\n","      <td>2.7500</td>\n","      <td>3.200000</td>\n","      <td>3.352941</td>\n","      <td>2.8750</td>\n","      <td>3.400000</td>\n","      <td>3.117647</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2.888889</td>\n","      <td>3.250</td>\n","      <td>2.7</td>\n","      <td>3.000000</td>\n","      <td>3.2500</td>\n","      <td>4.200000</td>\n","      <td>3.764706</td>\n","      <td>3.9375</td>\n","      <td>4.400000</td>\n","      <td>4.294118</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ecdf16e0-8890-49c5-bc3d-997206742f66')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-ecdf16e0-8890-49c5-bc3d-997206742f66 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-ecdf16e0-8890-49c5-bc3d-997206742f66');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-f42e9668-7335-4069-92fb-385fe3e46c16\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f42e9668-7335-4069-92fb-385fe3e46c16')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-f42e9668-7335-4069-92fb-385fe3e46c16 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"Bergh","summary":"{\n  \"name\": \"Bergh\",\n  \"rows\": 861,\n  \"fields\": [\n    {\n      \"column\": \"EP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7109031393896246,\n        \"min\": 1.0,\n        \"max\": 4.777777777777778,\n        \"num_unique_values\": 34,\n        \"samples\": [\n          1.1111111111111112,\n          1.5555555555555556,\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6846949273453097,\n        \"min\": 1.0,\n        \"max\": 4.25,\n        \"num_unique_values\": 27,\n        \"samples\": [\n          3.375,\n          2.875,\n          3.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5611063452228375,\n        \"min\": -3.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          3.3,\n          -2.5,\n          1.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5337214600757906,\n        \"min\": 1.0,\n        \"max\": 4.454545454545454,\n        \"num_unique_values\": 34,\n        \"samples\": [\n          3.090909090909091,\n          2.272727272727273,\n          1.2727272727272727\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"A1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5040151982408884,\n        \"min\": 1.875,\n        \"max\": 4.8125,\n        \"num_unique_values\": 45,\n        \"samples\": [\n          4.6875,\n          4.0,\n          4.1875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"A2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.47171013499934916,\n        \"min\": 2.3333333333333335,\n        \"max\": 4.866666666666666,\n        \"num_unique_values\": 38,\n        \"samples\": [\n          4.666666666666667,\n          4.8,\n          4.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"A3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4808565490061304,\n        \"min\": 1.9411764705882353,\n        \"max\": 4.882352941176471,\n        \"num_unique_values\": 46,\n        \"samples\": [\n          4.705882352941177,\n          3.8823529411764706,\n          1.9411764705882353\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"O1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.484553426658197,\n        \"min\": 2.0625,\n        \"max\": 5.0,\n        \"num_unique_values\": 46,\n        \"samples\": [\n          4.5625,\n          3.625,\n          2.9375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"O2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.467789610271841,\n        \"min\": 2.2,\n        \"max\": 4.866666666666666,\n        \"num_unique_values\": 39,\n        \"samples\": [\n          4.866666666666666,\n          4.466666666666667,\n          3.066666666666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"O3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5127063607641461,\n        \"min\": 2.1176470588235294,\n        \"max\": 5.0,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          4.882352941176471,\n          4.588235294117647,\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["#### The dataset\n","\n","We illustrate todays topic using a dataset from Bergh et al. (2016). Part of their\n","analysis consisted of a multigroup CFA, where ethnic prejudice *(EP)*, sexism *(SP)*,\n","sexual prejudice against gays and lesbians *(HP)*, and prejudice toward mentally\n","people with disabilities (DP) were modeled *as indicators of* a generalized prejudice\n","factor *(GP)*. The multigroup aspect comes in by exploring differences in CFA parameters across *gender*.\n","\n","### Fit the models\n","\n","Luckily, we don't have to specify all the models mentioned above by ourselves. Instead, we can use the `measurementInvariance()` function from the `semTools` package. We only need to specify few elements:\n","\n","1. )  The model equation (i.e. which items we want to include),\n","2. )  The dataset,\n","3. )  The grouping variable and\n","4. )  The estimator (We use a robust ML estimator since some of the prejudice measures deviate from normality).  \n","\n","Note. `strict = T` gives us a configural, metric (weak), scale (strong), strict and a fifth model. With `strict = F` we won't get the strict model."],"metadata":{"id":"XYns-0fybRdp"}},{"cell_type":"code","source":["ro.r(\"GP_model <- 'GP =~ EP + HP + DP + SP'\")\n","ro.r('minvfit <- measurementInvariance(model = GP_model, data = Bergh, group = \"gender\", estimator = \"MLR\", strict = T)')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ko0UFRMVbVG4","executionInfo":{"status":"ok","timestamp":1741899997861,"user_tz":-60,"elapsed":2278,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"7e4ae5b2-a49d-4c64-9602-6ecbfd2d5d13"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Measurement invariance models:\n","\n","Model 1 : fit.configural\n","Model 2 : fit.loadings\n","Model 3 : fit.intercepts\n","Model 4 : fit.residuals\n","Model 5 : fit.means\n","\n","\n","Scaled Chi-Squared Difference Test (method = “satorra.bentler.2001”)\n","\n","lavaan->lavTestLRT():  \n","   lavaan NOTE: The “Chisq” column contains standard test statistics, not the \n","   robust test that should be reported per model. A robust difference test is \n","   a function of two standard (not robust) statistics.\n","               Df    AIC    BIC    Chisq Chisq diff Df diff Pr(>Chisq)    \n","fit.configural  4 7376.1 7490.2   1.6552                                  \n","fit.loadings    7 7382.9 7482.8  14.4960     11.834       3   0.007972 ** \n","fit.intercepts 10 7417.7 7503.3  55.2875     47.833       3  2.311e-10 ***\n","fit.residuals  14 7429.8 7496.4  75.3689     12.468       4   0.014189 *  \n","fit.means      15 7482.4 7544.3 130.0375     49.267       1  2.234e-12 ***\n","---\n","Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n","\n","\n","Fit measures:\n","\n","               cfi.scaled rmsea.scaled cfi.scaled.delta rmsea.scaled.delta\n","fit.configural      1.000        0.000               NA                 NA\n","fit.loadings        0.988        0.046            0.012              0.046\n","fit.intercepts      0.914        0.102            0.074              0.056\n","fit.residuals       0.904        0.091            0.010              0.011\n","fit.means           0.816        0.122            0.088              0.031\n","\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: In addition: \n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: Warning message:\n","\n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: In measurementInvariance(model = GP_model, data = Bergh, group = \"gender\",  :\n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \n"," \n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]:  The measurementInvariance function is deprecated, and it will cease to be included in future versions of semTools. See help('semTools-deprecated) for details.\n","\n"]}]},{"cell_type":"markdown","source":["This code chunk fits four invariance models: configural, metric (weak), scale (strong), strict and a fifth model where, in addition to the indicator intercepts, the means of the latent variables are restricted to be equal as well. As mentioned above, we won't deal with the last model.  \n","\n","Each model is tested against the previous one, and a **significant result** indicates that the higher restricted model is significantly **worse** than the previous model. In our example, only configural variance holds as restricting the model parameters to match the assumptions of metric invariance results in a significantly worse fit.\n","\n","#### Select the best fitting model\n","\n","In our example we would go with the configural model, for which the output can be requested as follows:"],"metadata":{"id":"8ZGkAbIWbwIR"}},{"cell_type":"code","source":["# Extract only the configural model\n","ro.r(\"Fit_conf <- minvfit$fit.configural\")"],"metadata":{"id":"XoFxQWhibwwN","executionInfo":{"status":"ok","timestamp":1741899997863,"user_tz":-60,"elapsed":1,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["Try to investigate the `Fit_conf` using `summary()`. Remember to set `standardized = TRUE` & `fit.measures = TRUE`."],"metadata":{"id":"Xca05TMMb5F0"}},{"cell_type":"code","source":["summary_conf = ro.r(\"summary(Fit_conf, standardized = TRUE, fit.measures = TRUE)\")\n","print(summary_conf)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z3hGPJdGb5du","executionInfo":{"status":"ok","timestamp":1741899998774,"user_tz":-60,"elapsed":48,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"f6ef9ac7-44cf-4a10-d239-195462dbdfba"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["lavaan 0.6-19 ended normally after 45 iterations\n","\n","  Estimator                                         ML\n","  Optimization method                           NLMINB\n","  Number of model parameters                        24\n","\n","  Number of observations per group:                   \n","    male                                           249\n","    female                                         612\n","\n","Model Test User Model:\n","                                              Standard      Scaled\n","  Test Statistic                                 1.655       1.549\n","  Degrees of freedom                                 4           4\n","  P-value (Chi-square)                           0.799       0.818\n","  Scaling correction factor                                  1.068\n","    Yuan-Bentler correction (Mplus variant)                       \n","  Test statistic for each group:\n","    male                                         0.348       0.348\n","    female                                       1.201       1.201\n","\n","Model Test Baseline Model:\n","\n","  Test statistic                               716.580     530.342\n","  Degrees of freedom                                12          12\n","  P-value                                        0.000       0.000\n","  Scaling correction factor                                  1.351\n","\n","User Model versus Baseline Model:\n","\n","  Comparative Fit Index (CFI)                    1.000       1.000\n","  Tucker-Lewis Index (TLI)                       1.010       1.014\n","                                                                  \n","  Robust Comparative Fit Index (CFI)                         1.000\n","  Robust Tucker-Lewis Index (TLI)                            1.011\n","\n","Loglikelihood and Information Criteria:\n","\n","  Loglikelihood user model (H0)              -3664.027   -3664.027\n","  Scaling correction factor                                  1.284\n","      for the MLR correction                                      \n","  Loglikelihood unrestricted model (H1)      -3663.200   -3663.200\n","  Scaling correction factor                                  1.253\n","      for the MLR correction                                      \n","                                                                  \n","  Akaike (AIC)                                7376.055    7376.055\n","  Bayesian (BIC)                              7490.249    7490.249\n","  Sample-size adjusted Bayesian (SABIC)       7414.031    7414.031\n","\n","Root Mean Square Error of Approximation:\n","\n","  RMSEA                                          0.000       0.000\n","  90 Percent confidence interval - lower         0.000       0.000\n","  90 Percent confidence interval - upper         0.046       0.042\n","  P-value H_0: RMSEA <= 0.050                    0.961       0.971\n","  P-value H_0: RMSEA >= 0.080                    0.003       0.002\n","                                                                  \n","  Robust RMSEA                                               0.000\n","  90 Percent confidence interval - lower                     0.000\n","  90 Percent confidence interval - upper                     0.046\n","  P-value H_0: Robust RMSEA <= 0.050                         0.961\n","  P-value H_0: Robust RMSEA >= 0.080                         0.003\n","\n","Standardized Root Mean Square Residual:\n","\n","  SRMR                                           0.008       0.008\n","\n","Parameter Estimates:\n","\n","  Standard errors                             Sandwich\n","  Information bread                           Observed\n","  Observed information based on                Hessian\n","\n","\n","Group 1 [male]:\n","\n","Latent Variables:\n","                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n","  GP =~                                                                 \n","    EP                1.000                               0.489    0.717\n","    HP                1.452    0.289    5.024    0.000    0.709    0.387\n","    DP                0.766    0.100    7.670    0.000    0.375    0.685\n","    SP                1.137    0.153    7.409    0.000    0.556    0.805\n","\n","Intercepts:\n","                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n","   .EP                2.141    0.043   49.594    0.000    2.141    3.143\n","   .HP                1.379    0.116   11.883    0.000    1.379    0.753\n","   .DP                2.204    0.035   63.623    0.000    2.204    4.032\n","   .SP                2.466    0.044   56.376    0.000    2.466    3.573\n","\n","Variances:\n","                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n","   .EP                0.225    0.041    5.435    0.000    0.225    0.486\n","   .HP                2.851    0.362    7.873    0.000    2.851    0.850\n","   .DP                0.159    0.022    7.197    0.000    0.159    0.531\n","   .SP                0.168    0.031    5.341    0.000    0.168    0.352\n","    GP                0.239    0.044    5.450    0.000    1.000    1.000\n","\n","\n","Group 2 [female]:\n","\n","Latent Variables:\n","                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n","  GP =~                                                                 \n","    EP                1.000                               0.536    0.752\n","    HP                0.771    0.126    6.137    0.000    0.413    0.289\n","    DP                0.691    0.054   12.798    0.000    0.371    0.718\n","    SP                0.774    0.059   13.104    0.000    0.415    0.661\n","\n","Intercepts:\n","                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n","   .EP                1.927    0.029   66.895    0.000    1.927    2.704\n","   .HP                1.150    0.058   19.893    0.000    1.150    0.804\n","   .DP                1.999    0.021   95.793    0.000    1.999    3.872\n","   .SP                1.972    0.025   77.676    0.000    1.972    3.140\n","\n","Variances:\n","                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n","   .EP                0.221    0.029    7.526    0.000    0.221    0.434\n","   .HP                1.874    0.184   10.200    0.000    1.874    0.917\n","   .DP                0.129    0.017    7.420    0.000    0.129    0.484\n","   .SP                0.222    0.019   11.533    0.000    0.222    0.563\n","    GP                0.287    0.034    8.357    0.000    1.000    1.000\n","\n","\n"]}]},{"cell_type":"markdown","source":["For the interpretation of this output, please refer to the previous sessions.\n","\n","### Another Option\n","\n","Instead of using these generic invariance sequences of models, we can approach\n","multigroup CFA from a more hypothesis-driven direction. In the first model we are\n","going to fit, the loadings for ethnic minorities (EP), gays/lesbians (HP), and people\n","with disabilities (DP) are held equal across men and women. We keep the sexism\n","**(SP) loadings free**. Note that all intercepts are free to vary.  \n","\n","In `lavaan`, this can be achieved by using one of the following **two equivalent model formulations**.\n","In the first variant, we explicitly incorporate the loadings\n","restrictions in the model formulation. We specify a vector of length 2, the first\n","element denoting the loading for the first gender category and the second element\n","denoting the loading for the second category. Since we use the same loadings\n","symbols for both categories, they are restricted to be equal.\n","\n","#### Option 1 to specify the model"],"metadata":{"id":"c5aiR2GfceoI"}},{"cell_type":"code","source":["# First option to specify the model # CHECK: The values align with R but the readability not so much...\n","ro.r (\"GP_model <-'GP =~ c(v1,v1)*EP + c(v2,v2)*HP + c(v3,v3)*DP + SP'\") # The loading of SP is not fixed.\n","ro.r('fitBase <-lavaan::cfa(GP_model, data = Bergh, group = \"gender\", estimator = \"MLR\")')\n","ro.r(\"fitMeasures(fitBase)\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8qFpwJn7ciLx","executionInfo":{"status":"ok","timestamp":1741900001170,"user_tz":-60,"elapsed":290,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"e9e1f5f7-71ae-41e4-b191-1dee91b7333c"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 2.20000000e+01,  4.25165558e-03,  7.32135091e+00,  6.00000000e+00,\n","        2.92148336e-01,  6.85411314e+00,  6.00000000e+00,  3.34549818e-01,\n","        1.06816896e+00,  7.16580288e+02,  1.20000000e+01,  0.00000000e+00,\n","        5.30342427e+02,  1.20000000e+01,  0.00000000e+00,  1.35116530e+00,\n","        9.98124627e-01,  9.96249254e-01,  9.98352222e-01,  9.96704444e-01,\n","        9.98697343e-01,  9.97394686e-01,  9.96249254e-01,  9.79565860e-01,\n","        9.89782930e-01,  4.94891465e-01,  9.98140462e-01,  9.98124627e-01,\n","        9.96704444e-01,  9.74152122e-01,  9.87076061e-01,  4.93538031e-01,\n","        9.98371078e-01,  9.98352222e-01,  9.97394686e-01,  9.98697343e-01,\n","       -3.66686045e+03, -3.66319978e+03,  7.37772090e+03,  7.48239898e+03,\n","        8.61000000e+02,  7.41253284e+03,  1.25325348e+00,  1.19508682e+00,\n","        2.26176188e-02,  0.00000000e+00,  6.94429738e-02,  9.00000000e-01,\n","        7.89925895e-01,  5.00000000e-02,  1.69311900e-02,  8.00000000e-02,\n","        1.81842544e-02,  0.00000000e+00,  6.57201349e-02,  8.29630172e-01,\n","        1.05640614e-02,  1.87938378e-02,  0.00000000e+00,  6.94032961e-02,\n","        8.00895830e-01,  1.76915675e-02,  3.45567328e-02,  4.08880776e-02,\n","        2.78965693e-02,  2.78965693e-02,  3.30076659e-02,  2.89250947e-02,\n","        3.73421367e-02,  2.79544637e-02,  3.12849052e-02,  1.48178637e+03,\n","        1.97809969e+03,  9.99596007e-01,  9.98114702e-01,  2.14199144e-01,\n","        9.99232959e-01,  5.96066793e-02])"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["#### Option 2 to specify the model\n","\n","In the second variant, we restrict all the loadings to be equal across groups\n","using the `group.equal` argument. We then free up the SP loading through the\n","`group.partial` argument.\n"],"metadata":{"id":"3tqAvoyUcuUV"}},{"cell_type":"code","source":["# Second option to specify the model\n","ro.r(\"GP_model <- 'GP =~ EP + HP + DP + SP'\")\n","ro.r('fitBase <- lavaan::cfa(GP_model,data = Bergh, group = \"gender\", group.equal = c(\"loadings\"), group.partial = c(\"GP=~ SP\"), estimator = \"MLR\")')\n","ro.r(\"fitMeasures(fitBase)\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S2O07Js7dadR","executionInfo":{"status":"ok","timestamp":1741900002382,"user_tz":-60,"elapsed":422,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"d3d5438b-ff3a-467e-ab61-cc34e94b09a2"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 2.20000000e+01,  4.25165558e-03,  7.32135091e+00,  6.00000000e+00,\n","        2.92148336e-01,  6.85411314e+00,  6.00000000e+00,  3.34549818e-01,\n","        1.06816896e+00,  7.16580288e+02,  1.20000000e+01,  0.00000000e+00,\n","        5.30342427e+02,  1.20000000e+01,  0.00000000e+00,  1.35116530e+00,\n","        9.98124627e-01,  9.96249254e-01,  9.98352222e-01,  9.96704444e-01,\n","        9.98697343e-01,  9.97394686e-01,  9.96249254e-01,  9.79565860e-01,\n","        9.89782930e-01,  4.94891465e-01,  9.98140462e-01,  9.98124627e-01,\n","        9.96704444e-01,  9.74152122e-01,  9.87076061e-01,  4.93538031e-01,\n","        9.98371078e-01,  9.98352222e-01,  9.97394686e-01,  9.98697343e-01,\n","       -3.66686045e+03, -3.66319978e+03,  7.37772090e+03,  7.48239898e+03,\n","        8.61000000e+02,  7.41253284e+03,  1.25325348e+00,  1.19508682e+00,\n","        2.26176188e-02,  0.00000000e+00,  6.94429738e-02,  9.00000000e-01,\n","        7.89925895e-01,  5.00000000e-02,  1.69311900e-02,  8.00000000e-02,\n","        1.81842544e-02,  0.00000000e+00,  6.57201349e-02,  8.29630172e-01,\n","        1.05640614e-02,  1.87938378e-02,  0.00000000e+00,  6.94032961e-02,\n","        8.00895830e-01,  1.76915675e-02,  3.45567328e-02,  4.08880776e-02,\n","        2.78965693e-02,  2.78965693e-02,  3.30076659e-02,  2.89250947e-02,\n","        3.73421367e-02,  2.79544637e-02,  3.12849052e-02,  1.48178637e+03,\n","        1.97809969e+03,  9.99596007e-01,  9.98114702e-01,  2.14199144e-01,\n","        9.99232959e-01,  5.96066793e-02])"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["Both variants lead to the same results. Using the `fitMeasures(fitBase)`\n","call, we get a $\\chi^2$-value of 7.321 (df = 6, p = 0.292), a RMSEA of 0.023 with a 90%\n","CI of [0, 0.069], a CFI of 0.998, and an SRMR of 0.028. The model fits well.  \n","\n","Since the difference in intercepts between men and women is negligible for the\n","EP indicator, we can force the intercepts to be equal for this indicator. Let us build on\n","the second specification variant from above, in order to set up this model. Through\n","group.equal we **constrain all loadings and intercepts to be equal across groups**\n","and, subsequently, **free up the SP loading as well as the intercepts for DP, HP, and**\n","**SP** using `group.partial`:"],"metadata":{"id":"3t3g_kVGdv4s"}},{"cell_type":"code","source":["ro.r(\"GP_model <- 'GP =~ EP + HP + DP + SP'\")\n","\n","ro.r('fitBase1 <- lavaan::cfa(GP_model, data = Bergh,\\n'\n","      'group = \"gender\", group.equal = c(\"loadings\", \"intercepts\"),\\n'\n","      'group.partial = c(\"GP=~SP\", \"DP~1\", \"HP~1\", \"SP~1\"),\\n'\n","      'estimator = \"MLR\")')\n","\n","ro.r(\"fitMeasures(fitBase1)\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OFP7PJord1-Y","executionInfo":{"status":"ok","timestamp":1741900003806,"user_tz":-60,"elapsed":307,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"27c2a17f-08ee-414b-ac16-ff77ef91217a"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 2.20000000e+01,  4.25165558e-03,  7.32135091e+00,  6.00000000e+00,\n","        2.92148336e-01,  6.85411326e+00,  6.00000000e+00,  3.34549806e-01,\n","        1.06816894e+00,  7.16580288e+02,  1.20000000e+01,  0.00000000e+00,\n","        5.30342427e+02,  1.20000000e+01,  0.00000000e+00,  1.35116530e+00,\n","        9.98124627e-01,  9.96249254e-01,  9.98352222e-01,  9.96704444e-01,\n","        9.98697343e-01,  9.97394685e-01,  9.96249254e-01,  9.79565860e-01,\n","        9.89782930e-01,  4.94891465e-01,  9.98140462e-01,  9.98124627e-01,\n","        9.96704444e-01,  9.74152122e-01,  9.87076061e-01,  4.93538030e-01,\n","        9.98371077e-01,  9.98352222e-01,  9.97394685e-01,  9.98697343e-01,\n","       -3.66686045e+03, -3.66319978e+03,  7.37772090e+03,  7.48239898e+03,\n","        8.61000000e+02,  7.41253284e+03,  1.25325348e+00,  1.14728335e+00,\n","        2.26176188e-02,  0.00000000e+00,  6.94429738e-02,  9.00000000e-01,\n","        7.89925895e-01,  5.00000000e-02,  1.69311900e-02,  8.00000000e-02,\n","        1.81842557e-02,  0.00000000e+00,  6.57201359e-02,  8.29630162e-01,\n","        1.05640628e-02,  1.87938390e-02,  0.00000000e+00,  6.94032961e-02,\n","        8.00895827e-01,  1.76915673e-02,  3.45567379e-02,  4.08880836e-02,\n","        2.78965691e-02,  2.78965691e-02,  3.30076656e-02,  2.89250918e-02,\n","        3.73421329e-02,  2.79544638e-02,  3.12849044e-02,  1.48178637e+03,\n","        1.97809969e+03,  9.99596007e-01,  9.98114702e-01,  2.14199144e-01,\n","        9.99232959e-01,  5.96066793e-02])"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["Again, this model fits well. We now use this model as **baseline model** and\n","**compare it to two additional models**. First **(1)**, we **constrain the SP loading to be 0**\n","for the **women** (ingroup-outgroup model).We can specify this restriction directly in\n","the model specification through `c(NA,0)`. *NA means free to vary* across men (first\n","group), whereas the second element fixes the parameter to 0 for the women. Note\n","that this is quite a restrictive assumption."],"metadata":{"id":"YMM51t6QeU65"}},{"cell_type":"code","source":["ro.r(\"GP_model2 <- 'GP =~ c(v1,v1)*EP + c(v2,v2)*HP + c(v3,v3)*DP + c(NA, 0)*SP'\")\n","\n","ro.r('fitIO <- lavaan::cfa(GP_model2, data = Bergh,\\n'\n","      'group = \"gender\", group.equal = c(\"intercepts\"),\\n'\n","      'group.partial = c(\"DP~1\", \"HP~1\", \"SP~1\"),\\n'\n","      'estimator = \"MLR\")')\n","\n","ro.r(\"fitMeasures(fitIO)\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sBypc0SbeVd4","executionInfo":{"status":"ok","timestamp":1741900005380,"user_tz":-60,"elapsed":298,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"9641423a-f892-4792-f1be-d827bd0ef9a4"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 2.10000000e+01,  1.35746530e-01,  2.33755525e+02,  7.00000000e+00,\n","        0.00000000e+00,  1.98735302e+02,  7.00000000e+00,  0.00000000e+00,\n","        1.17621541e+00,  7.16580288e+02,  1.20000000e+01,  0.00000000e+00,\n","        5.30342427e+02,  1.20000000e+01,  0.00000000e+00,  1.35116530e+00,\n","        6.78169360e-01,  4.48290332e-01,  6.30099155e-01,  3.65884267e-01,\n","        6.77994193e-01,  4.47990045e-01,  4.48290332e-01,  4.40783170e-01,\n","        6.73790183e-01,  3.93044273e-01,  6.80437114e-01,  6.78169360e-01,\n","        3.65884267e-01,  3.57605443e-01,  6.25269842e-01,  3.64740741e-01,\n","        6.33633179e-01,  6.30099155e-01,  4.47990045e-01,  6.77994193e-01,\n","       -3.78007754e+03, -3.66319978e+03,  7.60215508e+03,  7.70207506e+03,\n","        8.61000000e+02,  7.63538466e+03,  1.25325348e+00,  1.11906623e+00,\n","        2.74311074e-01,  2.44736269e-01,  3.05059830e-01,  9.00000000e-01,\n","        0.00000000e+00,  5.00000000e-02,  1.00000000e+00,  8.00000000e-02,\n","        2.52240862e-01,  2.24930701e-01,  2.80629642e-01,  0.00000000e+00,\n","        1.00000000e+00,  2.73563956e-01,  2.41501536e-01,  3.07003195e-01,\n","        0.00000000e+00,  1.00000000e+00,  7.87104925e-02,  9.31315107e-02,\n","        1.48137318e-01,  1.48137318e-01,  1.75278438e-01,  1.73408453e-01,\n","        2.23869350e-01,  1.47992903e-01,  1.74465410e-01,  5.28139964e+01,\n","        6.90507520e+01,  9.91724502e-01,  9.66898008e-01,  2.47931126e-01,\n","        8.76620163e-01,  3.20273548e-01])"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["It gives a $\\chi^2$-value of 233.756 (df = 7, p = 0), a RMSEA of 0.274 with a 90%\n","CI of [0.245, 0.305], a CFI of 0.678, and an SRMR of 0.148. Bad fit.  \n","\n","In the next model **(2)**, we **restrict all the loadings to be equal** (**marginalization**\n","**model**). The intercepts have the same constraints as above."],"metadata":{"id":"-3Hukn-heiSE"}},{"cell_type":"code","source":["ro.r('fitMarg <- lavaan::cfa(GP_model, data = Bergh,\\n'\n","      'group = \"gender\", group.equal = c(\"loadings\", \"intercepts\"),\\n'\n","      'group.partial = c(\"DP~1\", \"HP~1\", \"SP~1\"),\\n'\n","      'estimator = \"MLR\")')\n","\n","ro.r(\"fitMeasures(fitMarg)\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bOKf86D9emTh","executionInfo":{"status":"ok","timestamp":1741900006723,"user_tz":-60,"elapsed":320,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"517ad4f2-77c8-46c7-bc1e-d5d06aa1bfb3"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 2.10000000e+01,  8.41811186e-03,  1.44959886e+01,  7.00000000e+00,\n","        4.30310073e-02,  1.34775671e+01,  7.00000000e+00,  6.12928392e-02,\n","        1.07556419e+00,  7.16580288e+02,  1.20000000e+01,  0.00000000e+00,\n","        5.30342427e+02,  1.20000000e+01,  0.00000000e+00,  1.35116530e+00,\n","        9.89361058e-01,  9.81761814e-01,  9.87503305e-01,  9.78577095e-01,\n","        9.90052292e-01,  9.82946787e-01,  9.81761814e-01,  9.65321030e-01,\n","        9.79770601e-01,  5.71532851e-01,  9.89436025e-01,  9.89361058e-01,\n","        9.78577095e-01,  9.56434938e-01,  9.74587047e-01,  5.68509111e-01,\n","        9.87622698e-01,  9.87503305e-01,  9.82946787e-01,  9.90052292e-01,\n","       -3.67044777e+03, -3.66319978e+03,  7.38289554e+03,  7.48281553e+03,\n","        8.61000000e+02,  7.41612512e+03,  1.25325348e+00,  1.10248592e+00,\n","        4.98745352e-02,  8.45147096e-03,  8.63560095e-02,  9.00000000e-01,\n","        4.48041192e-01,  5.00000000e-02,  9.26516415e-02,  8.00000000e-02,\n","        4.63628755e-02,  0.00000000e+00,  8.20635176e-02,  5.14076152e-01,\n","        6.20603424e-02,  4.80826651e-02,  0.00000000e+00,  8.64900078e-02,\n","        4.76996715e-01,  9.14857939e-02,  3.46405758e-02,  4.09872821e-02,\n","        3.61877722e-02,  3.61877722e-02,  4.28179495e-02,  3.03992933e-02,\n","        3.92453189e-02,  4.49043998e-02,  3.87798519e-02,  8.36528245e+02,\n","        1.09835456e+03,  9.99212175e-01,  9.96848701e-01,  2.49803044e-01,\n","        9.95656390e-01,  6.56167115e-02])"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["We get a $\\chi^2$-value of 14.496 (df = 7, p = 0.043), a RMSEA of 0.05 with a 90%\n","CI of [0.008, 0.086], a CFI of 0.989, and an SRMR of 0.036. In terms of goodness-of-fit statistics, we do not see much of a difference compared to the baseline model.\n","Let us do some model comparison. Since the marginalization model is nested in\n","the basemodel, we can apply the following $\\chi^2$-difference test. Note that a **significant**\n","**result suggests that the higher parametrized model fits significantly worse**."],"metadata":{"id":"wJW1foREempr"}},{"cell_type":"code","source":["print(ro.r(\"anova(fitMarg, fitBase1)\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5C-MeLn1evQz","executionInfo":{"status":"ok","timestamp":1741900007618,"user_tz":-60,"elapsed":10,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"20cd6116-623a-4628-8796-961fa3a8c264"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Scaled Chi-Squared Difference Test (method = “satorra.bentler.2001”)\n","\n","lavaan->lavTestLRT():  \n","   lavaan NOTE: The “Chisq” column contains standard test statistics, not the \n","   robust test that should be reported per model. A robust difference test is \n","   a function of two standard (not robust) statistics.\n","         Df    AIC    BIC   Chisq Chisq diff Df diff Pr(>Chisq)  \n","fitBase1  6 7377.7 7482.4  7.3214                                \n","fitMarg   7 7382.9 7482.8 14.4960     6.4063       1    0.01137 *\n","---\n","Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n","\n"]}]},{"cell_type":"markdown","source":["Even though significant, the AIC/BIC barely differ across the two groups,\n","and from the fit indices above, we learned that both models fit well. Thus, the\n","**marginalization model may be an attractive option to go with**.  \n","    \n","#### Didn't get it? No worries!\n","\n","The alternative approach presented here may be quite confusing as it wasn't covered in the lecture. So lets put it in words.  \n","\n","The goal here is to investigate the between-group measurement (in)variance of *one specific* indicator. In the approach mentioned before (and in the lecture) we investigated whether measurement invariance holds for *all* indicators.  \n","\n","As you might have guessed, the indicator we are investigating in this alternative approach is `SP`. Lets revisit the steps:\n","\n","1. We fit a model in which all loadings but the one from `SP` are fixed (`FitBase1`).\n","\n","2. We fit alternative models with alternative properties of the `SP` laodings (all the other loadings stay the same). (`GP_model2`: Fix `SP` loading for women but not for men; `fitMarg`: Fix all loadings).\n","\n","3. We compare model fits. Lets check the comparison of `fitMarg`and `fitBase1` again:"],"metadata":{"id":"ktEGJV7pe8yy"}},{"cell_type":"code","source":["print(ro.r(\"anova(fitMarg, fitBase1)\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PZ9A-LH0e9P5","executionInfo":{"status":"ok","timestamp":1741900008775,"user_tz":-60,"elapsed":15,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"395d6f0e-3754-4509-e214-c736743b28a1"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Scaled Chi-Squared Difference Test (method = “satorra.bentler.2001”)\n","\n","lavaan->lavTestLRT():  \n","   lavaan NOTE: The “Chisq” column contains standard test statistics, not the \n","   robust test that should be reported per model. A robust difference test is \n","   a function of two standard (not robust) statistics.\n","         Df    AIC    BIC   Chisq Chisq diff Df diff Pr(>Chisq)  \n","fitBase1  6 7377.7 7482.4  7.3214                                \n","fitMarg   7 7382.9 7482.8 14.4960     6.4063       1    0.01137 *\n","---\n","Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n","\n"]}]},{"cell_type":"markdown","source":["Before we look at the values, lets think about what this comparison is good for. In the `fitBase1` model we allow the loadings of `SP` to vary between men and women. In the `fitMarg` model we assume them to be equal for both groups. Now we can apply our 'normal' principle again: If the more restrictive model that assumes measurement invariance (`fitMarg`) **is not significantly worse** than the model that allows the loadings to vary (`fitBase1`) **we assume measurement invariance**. The critical point here is that we only investigated measurement invaraince for *one* indicator (`SP`) and not for the whole model (as done in the previous section)."],"metadata":{"id":"DWJJc7NkfEOC"}},{"cell_type":"markdown","source":["## 2. Measurement invariance across groups for qualitative item responses\n","\n","Measurement invariance can also be tested for dichotomous or polytomous (i.e. qualitative) item responses. In the Item Response Theory (IRT) this is known as **Differential Item Functioning (DIF)**. We can distinguish between two forms of DIF:  \n","\n","* **Uniform DIF:** the ICCs are shifted in location across subgroups, but they remain\n","parallel (i.e., a group main effect)\n","* **Nonuniform DIF:** the ICCs across subgroups are shifted, and they cross (i.e., an\n","interaction effect between group and the trait)  \n","\n","We focus on DIF detection using logistic regression (we skip tree-based DIF assessment as it wasn't covered in the statistics lecture yet).  \n","\n","The idea of this approach (Zumbo, 1999) is to specify a set of logistic regression equations and predict the original item responses from the person parameters $\\theta$ and the external grouping variable $z$. The following set of proportional odds models is formulated (Choi et al., 2011):  \n","\n","* $M_1$ : $logit(P(x_i)) = \\tau_0 + \\tau_1\\theta$\n","* $M_2$ : $logit(P(x_i)) = \\tau_0 + \\tau_1\\theta + \\tau_2z$\n","* $M_3$ : $logit(P(x_i)) = \\tau_0 + \\tau_1\\theta + \\tau_2z + \\tau_3\\theta z$\n","\n","We are interested in comparing the following models via the **LR-principle**:\n","\n","* $M_2$ vs. $M_1$: if significant, we have **uniform** DIF.\n","* $M_3$ vs. $M_2$: if significant, we have **nonuniform** DIF.\n","\n","### Load, prepare and inspect the dataset\n","\n","Try to load and inspect the dataset. It's called `YouthDep`. Extract the first 26 items and store the result in `cdi`. Also inspect your newly created subset."],"metadata":{"id":"V_Gpd405fEoj"}},{"cell_type":"code","source":["ro.r('data(\"YouthDep\")')\n","# Convert to Python\n","YouthDep_df = pandas2ri.rpy2py(ro.globalenv['YouthDep'])\n","# Select the first 26 columns\n","cdi = YouthDep_df.iloc[:, :26]\n","print(cdi.head())\n","\n","# Put data back into R\n","ro.globalenv['cdi'] = cdi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fXl8YBjrfG7q","executionInfo":{"status":"ok","timestamp":1741900010989,"user_tz":-60,"elapsed":274,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"1b0e5687-0f0b-49b3-da1b-894b3df8d612"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["   CDI1  CDI2r  CDI3  CDI4  CDI5r  CDI6  CDI7r  CDI8r  CDI10r  CDI11r  ...  \\\n","1     1      1     1     1      1     1      1      1       1       1  ...   \n","2     1      1     1     1      1     1      1      1       1       1  ...   \n","3     1      1     1     1      1     2      1      1       1       1  ...   \n","4     1      1     1     1      1     1      1      2       1       1  ...   \n","5     1      1     1     2      1     2      2      1       1       2  ...   \n","\n","   CDI18r  CDI19  CDI20  CDI21r  CDI22  CDI23  CDI24r  CDI25r  CDI26  CDI27  \n","1       1      1      2       2      1      1       1       1      2      1  \n","2       1      1      1       1      1      1       1       1      1      1  \n","3       1      1      1       1      1      1       1       1      1      1  \n","4       1      1      1       1      1      2       2       1      1      1  \n","5       1      1      1       1      2      1       3       1      1      1  \n","\n","[5 rows x 26 columns]\n"]}]},{"cell_type":"markdown","source":["#### The dataset\n","\n","As an example, we use a dataset from Vaughn-Coaxum et al. (2016) on youth\n","depression. The 26 items come from the Children’s Depression Inventory (CDI);\n","each item is scored on a scale from 0 to 2. The authors were interested in DIF\n","analyses on an external race variable (four categories). Note that the aim was\n","not to eliminate items from the CDI, which is a well-established scale. Rather,\n","the authors wanted to identify DIF items (which already gives useful substantive\n","information) and score all individuals in a “fair” way by means of group-specific\n","person parameter estimates for items flagged as DIF.\n","\n","### Fit the models\n","\n","Use the `lordif` function to fit the models (with this one function you will fit all the models described above). We want to use `YouthDep$race` as our grouping variable and our `cdi` subset as the dataset."],"metadata":{"id":"uNnka4r3gOva"}},{"cell_type":"code","source":["ro.r('cdiDIF <- lordif(cdi, YouthDep$race, criterion = \"Chisqr\")')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"avY4gletgUD-","executionInfo":{"status":"ok","timestamp":1741900049536,"user_tz":-60,"elapsed":37491,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"022a0bb4-7f2f-4ed3-abab-325d8d9d37bd"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":[" (mirt) | Iteration: 1, 21 items flagged for DIF (1,2,4,5,6,7,9,10,11,13,14,15,16,17,18,20,22,23,24,25,26)\n"," (mirt) | Iteration: 2, 20 items flagged for DIF (2,3,4,5,6,7,8,10,11,13,14,16,17,18,20,22,23,24,25,26)\n"," (mirt) | Iteration: 3, 20 items flagged for DIF (2,3,4,5,6,7,8,10,11,13,14,16,17,18,20,22,23,24,25,26)\n"]}]},{"cell_type":"markdown","source":["In total, 20 out of 26 items are flagged as DIF. Let us print out the p-values of\n","the LR-tests for the first three items:"],"metadata":{"id":"WliYem7vhIJx"}},{"cell_type":"code","source":["print(ro.r(\"cdiDIF$stats[1:3, 1:5]\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lRrR3PgKhH02","executionInfo":{"status":"ok","timestamp":1741900049537,"user_tz":-60,"elapsed":7,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"ace223e1-0d69-4411-dec3-5877ffdbba47"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["  item ncat chi12  chi13  chi23\n","1    1    2 0.352 0.3799 0.3718\n","2    2    2 0.000 0.0000 0.2084\n","3    3    2 0.000 0.0000 0.0022\n","\n"]}]},{"cell_type":"markdown","source":["We see that for the first item, none of the LR-$\\chi$2 values is significant. In fact, item\n","1 was not flagged. For the second item, $\\chi^2_{12}$ (i.e., M2 vs. M1) is significant, whereas $\\chi^2_{23}$\n","(i.e., M3 vs. M2) is not significant. Thus, the second item has uniform DIF. For\n","the third item, all p-values are significant; we have the case of nonuniform DIF.\n","Corresponding plots can be produced as follows:  \n","\n","**Note. The `plot()` function does not work in RMD with `lordif`objects.** If you want to see the plots, paste the following code chunk in a new R script (not an RMD!). You will end up with an empty plot in your plot window, however you can use the arrow button on the top left of the code window to cycle through the plots for every item. If you want to include the plots in your portfolio RMD follow this work-around: (1) Run the code chunk in a separate R script (adapted to your dataset) (2) Cycle through the plot using the arrow buttons in the plot window (3) Export the plot as a .png using the Export button in the plot window (4) insert the .png file in you RMD."],"metadata":{"id":"X66umCGrhgVB"}},{"cell_type":"code","source":["# CHECK: What do we do about that? See above..."],"metadata":{"id":"aauYHViEhhcH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let us print out the GRM parameters (discrimination, category boundaries) for\n","the six non-DIF items (non-DIF) and the first DIF item (I2):"],"metadata":{"id":"LwVRxZhYhtwd"}},{"cell_type":"code","source":["GRM = ro.r(\"cdiDIF$ipar.sparse\")\n","print(GRM.head(10))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VxTJXSsShuIg","executionInfo":{"status":"ok","timestamp":1741900049537,"user_tz":-60,"elapsed":4,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"7f4b5dc0-3dc4-4a4a-c2ab-f533e2629d86"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["            a       cb1      cb2\n","I1   2.055572 1.5197578       NA\n","I9   1.942808 1.6169260       NA\n","I12  1.224337 0.3175138 2.674436\n","I15  1.424712 1.1699027 2.507799\n","I19  2.107288 1.1153563       NA\n","I21  1.129338 1.9135221       NA\n","I2.1 1.638530 0.9251430       NA\n","I2.2 1.564181 0.9395047       NA\n","I2.3 1.611274 0.5323336       NA\n","I2.4 1.987255 1.0579461       NA\n","\n"]}]},{"cell_type":"markdown","source":["Note that for some items, there is only one category boundary. This results from\n","the fact that there were not enough observations in a particular category (here,\n","category 2) for parameter estimation. For such cases, `lordif` collapses categories\n","automatically. Item 2 was flagged as DIF.We get four sets of discrimination/boundary\n","parameters, one of each race category.  \n","\n","The calibrated, group-specific person parameter vector can be extracted using:"],"metadata":{"id":"lgE08sfIiNEX"}},{"cell_type":"code","source":["ro.r(\"ppar <- cdiDIF$calib.sparse$theta\")"],"metadata":{"id":"1g1b1aEViQKn","executionInfo":{"status":"ok","timestamp":1741900049538,"user_tz":-60,"elapsed":3,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["Based on the DIF subgroup structure, they are fairly scored, are on the same\n","scale, and can be subject to further analysis."],"metadata":{"id":"CWsRHy4giTYp"}},{"cell_type":"markdown","source":["## 3. Measurement invariance across time for quantitative item responses\n","\n","CFA can also be extended to longitudinal settings, where indicators are presented\n","to the same individual at multiple points in time $t$. Across the time points,\n","we can consider the same measurement invariance principles as in multigroup CFA\n","(configural, weak, and strong invariance). However, in longitudinal CFA we need\n","to account for **correlated residuals** (i.e. autoregressive effects) since we cannot assume that independence holds\n","across time points.\n","\n","### Load, prepare and inspect the dataset"],"metadata":{"id":"-NnxEx6SiT_n"}},{"cell_type":"code","source":["ro.r('data(\"SDOwave\")')\n","# Convert to Python\n","SDOwave = pandas2ri.rpy2py(ro.globalenv['SDOwave'])\n","print(SDOwave.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hg-MhIwPif7M","executionInfo":{"status":"ok","timestamp":1741900049552,"user_tz":-60,"elapsed":16,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"39c476e6-5aea-4d41-8d77-8e2deb259950"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["   I1.1996  I2.1996  I3.1996  I4.1996  I1.1997  I2.1997  I3.1997  I4.1997  \\\n","1      2.0      2.0      4.0      4.0      1.0      1.0      4.0      1.0   \n","2      1.0      1.0      2.0      2.0      1.0      1.0      2.0      3.0   \n","3      1.0      1.0      1.0      1.0      1.0      1.0      1.0      1.0   \n","4      2.0      2.0      3.0      3.0      2.0      2.0      2.0      2.0   \n","5      1.0      1.0      6.0      4.0      7.0      1.0      1.0      1.0   \n","\n","   I1.1998  I2.1998  I3.1998  I4.1998  I1.1999  I2.1999  I3.1999  I4.1999  \\\n","1      2.0      1.0      4.0      2.0      2.0      3.0      3.0      1.0   \n","2      4.0      2.0      5.0      4.0      3.0      2.0      4.0      4.0   \n","3      1.0      1.0      2.0      1.0      1.0      1.0      6.0      1.0   \n","4      2.0      2.0      2.0      2.0      2.0      1.0      1.0      1.0   \n","5      1.0      1.0      4.0      1.0      4.0      1.0      3.0      2.0   \n","\n","   I1.2000  I2.2000  I3.2000  I4.2000  \n","1      2.0      1.0      5.0      3.0  \n","2      1.0      1.0      3.0      3.0  \n","3      1.0      1.0      5.0      1.0  \n","4      1.0      1.0      1.0      1.0  \n","5      1.0      1.0      3.0      2.0  \n"]}]},{"cell_type":"markdown","source":["#### The dataset\n","\n","To illustrate longitudinal CFA, we use a dataset on social dominance orientation\n","(SDO; Sidanius and Pratto, 2001). SDO is assessed on the same individuals from\n","1996 to 2000 (Sidanius et al., 2010), involving the following four items, scored on a 7-point scale:  \n","\n","* It is probably a good thing that certain groups are at the top and other groups are at the bottom (I1).\n","\n","* Inferior groups should stay in their place (I2).\n","\n","* We should do what we can to equalize conditions for different groups (I3, reversed).\n","\n","* Increased social equality is beneficial to society (I4, reversed).\n","\n","For the moment, let us consider a simple latent variable structure where all four\n","items load on a general SDO dimension. We pick 2 years only: 1996 vs. 1998.  \n","\n","The most relevant model within this context is the **strong/scale invariance model**, which allows us to compare the latent means across the two time points. We restrict the factor loadings as well as the corresponding intercepts of each item to be equal in both measurement occasions (**strong/scale invariance**). Also, we need to allow for residual covariances (using the `~~` symbol in the syntax) for each item across time points. With this we account for autoregressive effects, which has to be done when modeling longitudinal data.\n","\n","### Fit the models\n","\n","We'll start with the scale invariance model and work our way down to lower levels of measurement invariance. (We exclude the strict invariance model here).\n","\n","We'll start with the scale invariance model and work our way down to lower levels of measurement invariance. (We exclude the strict invariance model here).\n","\n","#### Scale Invariance"],"metadata":{"id":"i9pVFo4PigHX"}},{"cell_type":"code","source":["# Specify the model\n","ro.r('model_scale <- \"'\n","      'SDO1996 =~ 1*I1.1996 + a2*I2.1996 + a3*I3.1996 + a4*I4.1996\\n'\n","      'SDO1998 =~ 1*I1.1998 + a2*I2.1998 + a3*I3.1998 + a4*I4.1998\\n'\n","      'SDO1996 ~~ SDO1998\\n'\n","      'I1.1996 ~ int1*1; I1.1998 ~ int1*1\\n'\n","      'I2.1996 ~ int2*1; I2.1998 ~ int2*1\\n'\n","      'I3.1996 ~ int3*1; I3.1998 ~ int3*1\\n'\n","      'I4.1996 ~ int4*1; I4.1998 ~ int4*1\\n'\n","      'I1.1996 ~~ I1.1998\\n'\n","      'I2.1996 ~~ I2.1998\\n'\n","      'I3.1996 ~~ I3.1998\\n'\n","      'I4.1996 ~~ I4.1998\\n'\n","      'SDO1996 ~ 0*1\\n'\n","      'SDO1998 ~ 1\"')\n","\n","# Fit the model\n","ro.r('fit_scale <- lavaan::cfa(model_scale, data = SDOwave, estimator = \"MLR\")')\n","\n","# Print the model output with fit measures and standardized estimates\n","summary_fit_scale = ro.r('summary(fit_scale, fit.measures=TRUE, standardized=TRUE)')\n","print(summary_fit_scale)"],"metadata":{"id":"a4EUpBoNiylc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741900248676,"user_tz":-60,"elapsed":595,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"d1c038f3-c035-49f8-811b-424e4612580b"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["lavaan 0.6-19 ended normally after 45 iterations\n","\n","  Estimator                                         ML\n","  Optimization method                           NLMINB\n","  Number of model parameters                        30\n","  Number of equality constraints                     7\n","\n","  Number of observations                           612\n","\n","Model Test User Model:\n","                                              Standard      Scaled\n","  Test Statistic                               315.748     203.519\n","  Degrees of freedom                                21          21\n","  P-value (Chi-square)                           0.000       0.000\n","  Scaling correction factor                                  1.551\n","    Yuan-Bentler correction (Mplus variant)                       \n","\n","Model Test Baseline Model:\n","\n","  Test statistic                              1993.536    1098.021\n","  Degrees of freedom                                28          28\n","  P-value                                        0.000       0.000\n","  Scaling correction factor                                  1.816\n","\n","User Model versus Baseline Model:\n","\n","  Comparative Fit Index (CFI)                    0.850       0.829\n","  Tucker-Lewis Index (TLI)                       0.800       0.773\n","                                                                  \n","  Robust Comparative Fit Index (CFI)                         0.854\n","  Robust Tucker-Lewis Index (TLI)                            0.806\n","\n","Loglikelihood and Information Criteria:\n","\n","  Loglikelihood user model (H0)              -7384.052   -7384.052\n","  Scaling correction factor                                  1.434\n","      for the MLR correction                                      \n","  Loglikelihood unrestricted model (H1)      -7226.178   -7226.178\n","  Scaling correction factor                                  1.718\n","      for the MLR correction                                      \n","                                                                  \n","  Akaike (AIC)                               14814.104   14814.104\n","  Bayesian (BIC)                             14915.689   14915.689\n","  Sample-size adjusted Bayesian (SABIC)      14842.669   14842.669\n","\n","Root Mean Square Error of Approximation:\n","\n","  RMSEA                                          0.151       0.119\n","  90 Percent confidence interval - lower         0.137       0.107\n","  90 Percent confidence interval - upper         0.166       0.131\n","  P-value H_0: RMSEA <= 0.050                    0.000       0.000\n","  P-value H_0: RMSEA >= 0.080                    1.000       1.000\n","                                                                  \n","  Robust RMSEA                                               0.148\n","  90 Percent confidence interval - lower                     0.130\n","  90 Percent confidence interval - upper                     0.167\n","  P-value H_0: Robust RMSEA <= 0.050                         0.000\n","  P-value H_0: Robust RMSEA >= 0.080                         1.000\n","\n","Standardized Root Mean Square Residual:\n","\n","  SRMR                                           0.096       0.096\n","\n","Parameter Estimates:\n","\n","  Standard errors                             Sandwich\n","  Information bread                           Observed\n","  Observed information based on                Hessian\n","\n","Latent Variables:\n","                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n","  SDO1996 =~                                                            \n","    I1.1996           1.000                               0.434    0.319\n","    I2.1996   (a2)    0.790    0.101    7.842    0.000    0.343    0.302\n","    I3.1996   (a3)    2.949    0.326    9.042    0.000    1.281    0.845\n","    I4.1996   (a4)    2.965    0.353    8.389    0.000    1.288    0.952\n","  SDO1998 =~                                                            \n","    I1.1998           1.000                               0.407    0.326\n","    I2.1998   (a2)    0.790    0.101    7.842    0.000    0.322    0.308\n","    I3.1998   (a3)    2.949    0.326    9.042    0.000    1.200    0.813\n","    I4.1998   (a4)    2.965    0.353    8.389    0.000    1.207    0.930\n","\n","Covariances:\n","                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n","  SDO1996 ~~                                                            \n","    SDO1998           0.098    0.023    4.275    0.000    0.552    0.552\n"," .I1.1996 ~~                                                            \n","   .I1.1998           0.425    0.075    5.697    0.000    0.425    0.280\n"," .I2.1996 ~~                                                            \n","   .I2.1998           0.258    0.072    3.594    0.000    0.258    0.240\n"," .I3.1996 ~~                                                            \n","   .I3.1998           0.220    0.076    2.911    0.004    0.220    0.316\n"," .I4.1996 ~~                                                            \n","   .I4.1998          -0.109    0.052   -2.078    0.038   -0.109   -0.555\n","\n","Intercepts:\n","                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n","   .I1.1996 (int1)    2.064    0.045   45.732    0.000    2.064    1.516\n","   .I1.1998 (int1)    2.064    0.045   45.732    0.000    2.064    1.654\n","   .I2.1996 (int2)    1.633    0.039   42.279    0.000    1.633    1.438\n","   .I2.1998 (int2)    1.633    0.039   42.279    0.000    1.633    1.562\n","   .I3.1996 (int3)    2.765    0.060   46.233    0.000    2.765    1.825\n","   .I3.1998 (int3)    2.765    0.060   46.233    0.000    2.765    1.874\n","   .I4.1996 (int4)    2.428    0.054   44.827    0.000    2.428    1.795\n","   .I4.1998 (int4)    2.428    0.054   44.827    0.000    2.428    1.872\n","    SDO1996           0.000                               0.000    0.000\n","    SDO1998          -0.047    0.019   -2.432    0.015   -0.115   -0.115\n","\n","Variances:\n","                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n","   .I1.1996           1.664    0.126   13.170    0.000    1.664    0.898\n","   .I2.1996           1.172    0.131    8.960    0.000    1.172    0.909\n","   .I3.1996           0.656    0.103    6.377    0.000    0.656    0.286\n","   .I4.1996           0.170    0.079    2.145    0.032    0.170    0.093\n","   .I1.1998           1.391    0.104   13.370    0.000    1.391    0.894\n","   .I2.1998           0.989    0.144    6.874    0.000    0.989    0.905\n","   .I3.1998           0.739    0.102    7.275    0.000    0.739    0.339\n","   .I4.1998           0.226    0.082    2.756    0.006    0.226    0.134\n","    SDO1996           0.189    0.043    4.363    0.000    1.000    1.000\n","    SDO1998           0.166    0.035    4.756    0.000    1.000    1.000\n","\n","\n"]}]},{"cell_type":"markdown","source":["The parameters of main interest are the latent variable means (however, this has nothing to do with measurement invariance but can be used to compare latent score bewteen time points):"],"metadata":{"id":"lpHPtAwdW5SP"}},{"cell_type":"code","source":["print(ro.r(\"parameterEstimates(fit_scale)[22:23,]\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eY9j9wDIW5ui","executionInfo":{"status":"ok","timestamp":1741900501244,"user_tz":-60,"elapsed":14,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"a7530526-ddd0-4390-c388-ecce8d4539b4"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["       lhs op rhs label    est    se      z pvalue ci.lower ci.upper\n","22 SDO1996 ~1            0.000 0.000     NA     NA    0.000    0.000\n","23 SDO1998 ~1           -0.047 0.019 -2.432  0.015   -0.085   -0.009\n","\n"]}]},{"cell_type":"markdown","source":["We see that the mean for 1996 was fixed to 0 and is therefore used as the reference\n","year. The second line suggests that there is a significant decrease in SDO from 1996\n","to 1998.  \n","\n","Note that a **weak/metric invariance** version of this model can be fitted by *restricting both*\n","*latent means to 0* and *freeing up the intercepts*. For a **configural invariance** version,\n","the *loadings need to be freed up as well* (first two syntax lines). For a **strict invariance** version, *intercepts, loadings and residuals* need to be *fixed*.  \n","If we do not want to do this by hand, the `longInvariance` function from `semTools` can be used\n","to establish such a generic sequence (similar to the `measurementInvariance` function used above).\n","Using the `anova` function, the models can be again tested against each other.  \n","\n","Lets fit a **weak/metric invariance** model.\n","\n","#### Metric Invariance\n","\n","Adapt the code from the scale model to fit a metric model by freeing up the intercepts and restrict both latent variables to zero. Name your model `model.metric`."],"metadata":{"id":"ExxJrA45XKGP"}},{"cell_type":"code","source":["# Specify the model\n","ro.r('model_metric <- \"'\n","      'SDO1996 =~ 1*I1.1996 + a2*I2.1996 + a3*I3.1996 + a4*I4.1996\\n'\n","      'SDO1998 =~ 1*I1.1998 + a2*I2.1998 + a3*I3.1998 + a4*I4.1998\\n'\n","      'SDO1996 ~~ SDO1998\\n'\n","      'I1.1996 ~ 1; I1.1998 ~ 1\\n'\n","      'I2.1996 ~ 1; I2.1998 ~ 1\\n'\n","      'I3.1996 ~ 1; I3.1998 ~ 1\\n'\n","      'I4.1996 ~ 1; I4.1998 ~ 1\\n'\n","      'I1.1996 ~~ I1.1998\\n'\n","      'I2.1996 ~~ I2.1998\\n'\n","      'I3.1996 ~~ I3.1998\\n'\n","      'I4.1996 ~~ I4.1998\\n'\n","      'SDO1996 ~ 0*1\\n'\n","      'SDO1998 ~ 0*1\"')\n","\n","# Fit the model\n","ro.r('fit_metric <- lavaan::cfa(model_metric, data = SDOwave, estimator = \"MLR\")')\n","\n","# Print the model output with fit measures and standardized estimates\n","summary_fit_metric = ro.r('summary(fit_metric, fit.measures=TRUE, standardized=TRUE)')\n","print(summary_fit_metric)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mpi7xtuzXNh0","executionInfo":{"status":"ok","timestamp":1741900683289,"user_tz":-60,"elapsed":803,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"294e0d40-96e1-4291-a4e2-91a52e2396c2"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["lavaan 0.6-19 ended normally after 43 iterations\n","\n","  Estimator                                         ML\n","  Optimization method                           NLMINB\n","  Number of model parameters                        29\n","  Number of equality constraints                     3\n","\n","  Number of observations                           612\n","\n","Model Test User Model:\n","                                              Standard      Scaled\n","  Test Statistic                               310.762     189.360\n","  Degrees of freedom                                18          18\n","  P-value (Chi-square)                           0.000       0.000\n","  Scaling correction factor                                  1.641\n","    Yuan-Bentler correction (Mplus variant)                       \n","\n","Model Test Baseline Model:\n","\n","  Test statistic                              1993.536    1098.021\n","  Degrees of freedom                                28          28\n","  P-value                                        0.000       0.000\n","  Scaling correction factor                                  1.816\n","\n","User Model versus Baseline Model:\n","\n","  Comparative Fit Index (CFI)                    0.851       0.840\n","  Tucker-Lewis Index (TLI)                       0.768       0.751\n","                                                                  \n","  Robust Comparative Fit Index (CFI)                         0.855\n","  Robust Tucker-Lewis Index (TLI)                            0.775\n","\n","Loglikelihood and Information Criteria:\n","\n","  Loglikelihood user model (H0)              -7381.559   -7381.559\n","  Scaling correction factor                                  1.588\n","      for the MLR correction                                      \n","  Loglikelihood unrestricted model (H1)      -7226.178   -7226.178\n","  Scaling correction factor                                  1.718\n","      for the MLR correction                                      \n","                                                                  \n","  Akaike (AIC)                               14815.117   14815.117\n","  Bayesian (BIC)                             14929.952   14929.952\n","  Sample-size adjusted Bayesian (SABIC)      14847.408   14847.408\n","\n","Root Mean Square Error of Approximation:\n","\n","  RMSEA                                          0.163       0.125\n","  90 Percent confidence interval - lower         0.147       0.112\n","  90 Percent confidence interval - upper         0.179       0.137\n","  P-value H_0: RMSEA <= 0.050                    0.000       0.000\n","  P-value H_0: RMSEA >= 0.080                    1.000       1.000\n","                                                                  \n","  Robust RMSEA                                               0.160\n","  90 Percent confidence interval - lower                     0.140\n","  90 Percent confidence interval - upper                     0.181\n","  P-value H_0: Robust RMSEA <= 0.050                         0.000\n","  P-value H_0: Robust RMSEA >= 0.080                         1.000\n","\n","Standardized Root Mean Square Residual:\n","\n","  SRMR                                           0.096       0.096\n","\n","Parameter Estimates:\n","\n","  Standard errors                             Sandwich\n","  Information bread                           Observed\n","  Observed information based on                Hessian\n","\n","Latent Variables:\n","                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n","  SDO1996 =~                                                            \n","    I1.1996           1.000                               0.437    0.321\n","    I2.1996   (a2)    0.781    0.101    7.726    0.000    0.341    0.301\n","    I3.1996   (a3)    2.946    0.326    9.044    0.000    1.287    0.848\n","    I4.1996   (a4)    2.938    0.348    8.447    0.000    1.284    0.950\n","  SDO1998 =~                                                            \n","    I1.1998           1.000                               0.410    0.328\n","    I2.1998   (a2)    0.781    0.101    7.726    0.000    0.320    0.306\n","    I3.1998   (a3)    2.946    0.326    9.044    0.000    1.206    0.816\n","    I4.1998   (a4)    2.938    0.348    8.447    0.000    1.203    0.928\n","\n","Covariances:\n","                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n","  SDO1996 ~~                                                            \n","    SDO1998           0.099    0.023    4.305    0.000    0.553    0.553\n"," .I1.1996 ~~                                                            \n","   .I1.1998           0.425    0.075    5.700    0.000    0.425    0.279\n"," .I2.1996 ~~                                                            \n","   .I2.1998           0.259    0.072    3.618    0.000    0.259    0.241\n"," .I3.1996 ~~                                                            \n","   .I3.1998           0.217    0.076    2.871    0.004    0.217    0.316\n"," .I4.1996 ~~                                                            \n","   .I4.1998          -0.104    0.052   -1.991    0.046   -0.104   -0.507\n","\n","Intercepts:\n","                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n","   .I1.1996           2.042    0.056   36.593    0.000    2.042    1.500\n","   .I1.1998           2.034    0.050   40.688    0.000    2.034    1.630\n","   .I2.1996           1.673    0.047   35.833    0.000    1.673    1.475\n","   .I2.1998           1.564    0.042   37.580    0.000    1.564    1.498\n","   .I3.1996           2.742    0.061   45.150    0.000    2.742    1.807\n","   .I3.1998           2.655    0.061   43.803    0.000    2.655    1.797\n","   .I4.1996           2.441    0.055   44.387    0.000    2.441    1.806\n","   .I4.1998           2.273    0.052   43.523    0.000    2.273    1.753\n","    SDO1996           0.000                               0.000    0.000\n","    SDO1998           0.000                               0.000    0.000\n","\n","Variances:\n","                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n","   .I1.1996           1.663    0.127   13.068    0.000    1.663    0.897\n","   .I2.1996           1.170    0.130    9.031    0.000    1.170    0.910\n","   .I3.1996           0.646    0.105    6.166    0.000    0.646    0.280\n","   .I4.1996           0.180    0.079    2.273    0.023    0.180    0.098\n","   .I1.1998           1.390    0.104   13.420    0.000    1.390    0.892\n","   .I2.1998           0.987    0.144    6.837    0.000    0.987    0.906\n","   .I3.1998           0.729    0.100    7.310    0.000    0.729    0.334\n","   .I4.1998           0.234    0.081    2.896    0.004    0.234    0.139\n","    SDO1996           0.191    0.044    4.372    0.000    1.000    1.000\n","    SDO1998           0.168    0.035    4.802    0.000    1.000    1.000\n","\n","\n"]}]},{"cell_type":"markdown","source":["Note that the values in the `intercepts` section are now varying.\n","\n","Again, we can extract latent variable means (however, this has again nothing to do with measurement invariance):"],"metadata":{"id":"9fqJ4FdvX2Wj"}},{"cell_type":"code","source":["print(ro.r(\"parameterEstimates(fit_metric)[22:23,]\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3R5jwcURX2yB","executionInfo":{"status":"ok","timestamp":1741900724333,"user_tz":-60,"elapsed":9,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"a767fe13-85a7-47fc-cf22-e11a41bb57c0"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["       lhs op rhs label est se  z pvalue ci.lower ci.upper\n","22 SDO1996 ~1             0  0 NA     NA        0        0\n","23 SDO1998 ~1             0  0 NA     NA        0        0\n","\n"]}]},{"cell_type":"markdown","source":["Lets continue with a **configural variance** model.\n","\n","#### Configural Invariance\n","\n","Adapt the code from the metric model to fit a configural model by freeing up the loadings as well (first two syntax lines). Name your model `model.configural`."],"metadata":{"id":"tW2wYxfvYIsS"}},{"cell_type":"code","source":["# Specify the model\n","ro.r('model_configural <- \"'\n","      'SDO1996 =~ 1*I1.1996 + I2.1996 + I3.1996 + I4.1996\\n'\n","      'SDO1998 =~ 1*I1.1998 + I2.1998 + I3.1998 + I4.1998\\n'\n","      'SDO1996 ~~ SDO1998\\n'\n","      'I1.1996 ~ 1; I1.1998 ~ 1\\n'\n","      'I2.1996 ~ 1; I2.1998 ~ 1\\n'\n","      'I3.1996 ~ 1; I3.1998 ~ 1\\n'\n","      'I4.1996 ~ 1; I4.1998 ~ 1\\n'\n","      'I1.1996 ~~ I1.1998\\n'\n","      'I2.1996 ~~ I2.1998\\n'\n","      'I3.1996 ~~ I3.1998\\n'\n","      'I4.1996 ~~ I4.1998\\n'\n","      'SDO1996 ~ 0*1\\n'\n","      'SDO1998 ~ 0*1\"')\n","\n","# Fit the model\n","ro.r('fit_configural <- lavaan::cfa(model_configural, data = SDOwave, estimator = \"MLR\")')\n","\n","# Print the model output with fit measures and standardized estimates\n","summary_fit_configural = ro.r('summary(fit_configural, fit.measures=TRUE, standardized=TRUE)')\n","print(summary_fit_configural)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AbJuj8aSYKI_","executionInfo":{"status":"ok","timestamp":1741900838316,"user_tz":-60,"elapsed":1095,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"eb5740c3-f871-46e0-de16-b6388a2042f3"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["lavaan 0.6-19 ended normally after 61 iterations\n","\n","  Estimator                                         ML\n","  Optimization method                           NLMINB\n","  Number of model parameters                        29\n","\n","  Number of observations                           612\n","\n","Model Test User Model:\n","                                              Standard      Scaled\n","  Test Statistic                               301.687     175.637\n","  Degrees of freedom                                15          15\n","  P-value (Chi-square)                           0.000       0.000\n","  Scaling correction factor                                  1.718\n","    Yuan-Bentler correction (Mplus variant)                       \n","\n","Model Test Baseline Model:\n","\n","  Test statistic                              1993.536    1098.021\n","  Degrees of freedom                                28          28\n","  P-value                                        0.000       0.000\n","  Scaling correction factor                                  1.816\n","\n","User Model versus Baseline Model:\n","\n","  Comparative Fit Index (CFI)                    0.854       0.850\n","  Tucker-Lewis Index (TLI)                       0.728       0.720\n","                                                                  \n","  Robust Comparative Fit Index (CFI)                         0.858\n","  Robust Tucker-Lewis Index (TLI)                            0.735\n","\n","Loglikelihood and Information Criteria:\n","\n","  Loglikelihood user model (H0)              -7377.021   -7377.021\n","  Scaling correction factor                                  1.719\n","      for the MLR correction                                      \n","  Loglikelihood unrestricted model (H1)      -7226.178   -7226.178\n","  Scaling correction factor                                  1.718\n","      for the MLR correction                                      \n","                                                                  \n","  Akaike (AIC)                               14812.043   14812.043\n","  Bayesian (BIC)                             14940.128   14940.128\n","  Sample-size adjusted Bayesian (SABIC)      14848.059   14848.059\n","\n","Root Mean Square Error of Approximation:\n","\n","  RMSEA                                          0.177       0.132\n","  90 Percent confidence interval - lower         0.160       0.119\n","  90 Percent confidence interval - upper         0.194       0.146\n","  P-value H_0: RMSEA <= 0.050                    0.000       0.000\n","  P-value H_0: RMSEA >= 0.080                    1.000       1.000\n","                                                                  \n","  Robust RMSEA                                               0.173\n","  90 Percent confidence interval - lower                     0.151\n","  90 Percent confidence interval - upper                     0.197\n","  P-value H_0: Robust RMSEA <= 0.050                         0.000\n","  P-value H_0: Robust RMSEA >= 0.080                         1.000\n","\n","Standardized Root Mean Square Residual:\n","\n","  SRMR                                           0.092       0.092\n","\n","Parameter Estimates:\n","\n","  Standard errors                             Sandwich\n","  Information bread                           Observed\n","  Observed information based on                Hessian\n","\n","Latent Variables:\n","                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n","  SDO1996 =~                                                            \n","    I1.1996           1.000                               0.493    0.358\n","    I2.1996           0.814    0.088    9.287    0.000    0.401    0.349\n","    I3.1996           2.562    0.314    8.164    0.000    1.264    0.842\n","    I4.1996           2.622    0.339    7.734    0.000    1.293    0.952\n","  SDO1998 =~                                                            \n","    I1.1998           1.000                               0.363    0.294\n","    I2.1998           0.729    0.177    4.124    0.000    0.265    0.258\n","    I3.1998           3.452    0.561    6.154    0.000    1.254    0.837\n","    I4.1998           3.242    0.568    5.708    0.000    1.178    0.912\n","\n","Covariances:\n","                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n","  SDO1996 ~~                                                            \n","    SDO1998           0.099    0.023    4.318    0.000    0.553    0.553\n"," .I1.1996 ~~                                                            \n","   .I1.1998           0.423    0.074    5.745    0.000    0.423    0.279\n"," .I2.1996 ~~                                                            \n","   .I2.1998           0.257    0.071    3.628    0.000    0.257    0.240\n"," .I3.1996 ~~                                                            \n","   .I3.1998           0.210    0.075    2.813    0.005    0.210    0.316\n"," .I4.1996 ~~                                                            \n","   .I4.1998          -0.095    0.052   -1.842    0.065   -0.095   -0.436\n","\n","Intercepts:\n","                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n","   .I1.1996           2.042    0.056   36.593    0.000    2.042    1.483\n","   .I1.1998           2.034    0.050   40.688    0.000    2.034    1.649\n","   .I2.1996           1.673    0.047   35.833    0.000    1.673    1.455\n","   .I2.1998           1.564    0.042   37.580    0.000    1.564    1.520\n","   .I3.1996           2.742    0.061   45.150    0.000    2.742    1.827\n","   .I3.1998           2.655    0.061   43.803    0.000    2.655    1.771\n","   .I4.1996           2.441    0.055   44.387    0.000    2.441    1.798\n","   .I4.1998           2.273    0.052   43.523    0.000    2.273    1.761\n","    SDO1996           0.000                               0.000    0.000\n","    SDO1998           0.000                               0.000    0.000\n","\n","Variances:\n","                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n","   .I1.1996           1.652    0.128   12.945    0.000    1.652    0.872\n","   .I2.1996           1.161    0.130    8.930    0.000    1.161    0.878\n","   .I3.1996           0.655    0.097    6.771    0.000    0.655    0.291\n","   .I4.1996           0.171    0.078    2.210    0.027    0.171    0.093\n","   .I1.1998           1.390    0.103   13.489    0.000    1.390    0.913\n","   .I2.1998           0.988    0.144    6.846    0.000    0.988    0.934\n","   .I3.1998           0.675    0.114    5.925    0.000    0.675    0.300\n","   .I4.1998           0.279    0.097    2.866    0.004    0.279    0.167\n","    SDO1996           0.243    0.058    4.205    0.000    1.000    1.000\n","    SDO1998           0.132    0.041    3.257    0.001    1.000    1.000\n","\n","\n"]}]},{"cell_type":"markdown","source":["#### Model Comparison\n","\n","To assess which model provides a better fit (and therefore to assess which level of measurement invariance holds) we can use the `anova()` function.  \n","\n","Lets first compare the **configural model** and the **metric model**."],"metadata":{"id":"K0pRi3lzYfri"}},{"cell_type":"code","source":["print(ro.r(\"anova(fit_configural, fit_metric)\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8n_UUEHyYj2J","executionInfo":{"status":"ok","timestamp":1741900906879,"user_tz":-60,"elapsed":10,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"00b5b2b3-eda5-4c53-a6de-f59e74ab8831"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Scaled Chi-Squared Difference Test (method = “satorra.bentler.2001”)\n","\n","lavaan->lavTestLRT():  \n","   lavaan NOTE: The “Chisq” column contains standard test statistics, not the \n","   robust test that should be reported per model. A robust difference test is \n","   a function of two standard (not robust) statistics.\n","               Df   AIC   BIC  Chisq Chisq diff Df diff Pr(>Chisq)  \n","fit_configural 15 14812 14940 301.69                                \n","fit_metric     18 14815 14930 310.76     7.2119       3    0.06544 .\n","---\n","Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n","\n"]}]},{"cell_type":"markdown","source":["We see that the metric model fits worse than the configural model. This is no suprise as we include more restrictions in the metric model. However, the fit is not significantly worse (p = .0654) and the BIC even favors the metric model. From this we may conclude that metric invariance holds but there is a huge BUT (see below).\n","\n","Next, lets compare the **metric model** and the **scale model**."],"metadata":{"id":"F_a8vFFOYu8R"}},{"cell_type":"code","source":["print(ro.r(\"anova(fit_metric, fit_scale)\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hKT2r74DYvfa","executionInfo":{"status":"ok","timestamp":1741900962524,"user_tz":-60,"elapsed":17,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"95a8e877-c63e-4412-e52b-38deaa18029f"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Scaled Chi-Squared Difference Test (method = “satorra.bentler.2001”)\n","\n","lavaan->lavTestLRT():  \n","   lavaan NOTE: The “Chisq” column contains standard test statistics, not the \n","   robust test that should be reported per model. A robust difference test is \n","   a function of two standard (not robust) statistics.\n","           Df   AIC   BIC  Chisq Chisq diff Df diff Pr(>Chisq)\n","fit_metric 18 14815 14930 310.76                              \n","fit_scale  21 14814 14916 315.75     4.9207       3     0.1777\n","\n"]}]},{"cell_type":"markdown","source":["From this comparison we can conclude that scale invariance holds as the scale model is not significantly worse than the metric model.  \n","\n","Now to the **BUT**: You can see in the model output of the **configural model** that the fit is quite bad (e.g. RMSEA =  0.177 (> .08)). This is not too surprising since research has shown that there are two subdimensions of SDO (Ho et al., 2015):\n","anti-egalitarianism and dominance. According to the theory, the first two items are\n","supposed to load on the dominance dimension (SDO-D), whereas the remaining two\n","items load on anti-egalitarianism (SDO-E).  \n","\n","Therefore, we should be cautious with interpreting the comparisons above and first make sure that we find a good fitting model to our data."],"metadata":{"id":"D5hRDACoY4rL"}}],"metadata":{"colab":{"provenance":[{"file_id":"1shSM8oE3V3nElvkpfKPtfJNamsVKnTSR","timestamp":1741293629262},{"file_id":"1oY59GO8mlzEJZlf-csY2pKRUXDCCIMFo","timestamp":1741164113567},{"file_id":"1_Hdy9GX2W03RQoKnijnEid9-KJzzTmJi","timestamp":1740862927421}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}