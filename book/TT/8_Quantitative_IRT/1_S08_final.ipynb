{"cells":[{"cell_type":"markdown","metadata":{"id":"0dtwBaFyRwzF"},"source":["# Testing rpy2: Princals\n","\n","We first start with setting up the environment and install the required R and Python packages:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"dUHdGXyHlg7p","outputId":"f2bf80b3-8ef4-459c-d6cf-015be39cf104","executionInfo":{"status":"ok","timestamp":1741813010356,"user_tz":-60,"elapsed":98210,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","R version 4.4.3 (2025-02-28) -- \"Trophy Case\"\n","Copyright (C) 2025 The R Foundation for Statistical Computing\n","Platform: x86_64-pc-linux-gnu\n","\n","R is free software and comes with ABSOLUTELY NO WARRANTY.\n","You are welcome to redistribute it under certain conditions.\n","Type 'license()' or 'licence()' for distribution details.\n","\n","  Natural language support but running in an English locale\n","\n","R is a collaborative project with many contributors.\n","Type 'contributors()' for more information and\n","'citation()' on how to cite R or R packages in publications.\n","\n","Type 'demo()' for some demos, 'help()' for on-line help, or\n","'help.start()' for an HTML browser interface to help.\n","Type 'q()' to quit R.\n","\n","> install.packages(c('lavaan','semPlot', 'psych'), repos='https://cran.uni-muenster.de', quiet=FALSE)\n","Installing packages into ‘/usr/local/lib/R/site-library’\n","(as ‘lib’ is unspecified)\n","also installing the dependencies ‘arm’, ‘mi’, ‘lme4’, ‘sem’, ‘rockchalk’, ‘OpenMx’\n","\n","trying URL 'https://cran.uni-muenster.de/src/contrib/arm_1.14-4.tar.gz'\n","Content type 'application/x-gzip' length 79825 bytes (77 KB)\n","==================================================\n","downloaded 77 KB\n","\n","trying URL 'https://cran.uni-muenster.de/src/contrib/mi_1.1.tar.gz'\n","Content type 'application/x-gzip' length 806468 bytes (787 KB)\n","==================================================\n","downloaded 787 KB\n","\n","trying URL 'https://cran.uni-muenster.de/src/contrib/lme4_1.1-36.tar.gz'\n","Content type 'application/x-gzip' length 3294834 bytes (3.1 MB)\n","==================================================\n","downloaded 3.1 MB\n","\n","trying URL 'https://cran.uni-muenster.de/src/contrib/sem_3.1-16.tar.gz'\n","Content type 'application/x-gzip' length 171827 bytes (167 KB)\n","==================================================\n","downloaded 167 KB\n","\n","trying URL 'https://cran.uni-muenster.de/src/contrib/rockchalk_1.8.157.tar.gz'\n","Content type 'application/x-gzip' length 2426057 bytes (2.3 MB)\n","==================================================\n","downloaded 2.3 MB\n","\n","trying URL 'https://cran.uni-muenster.de/src/contrib/OpenMx_2.21.13.tar.gz'\n","Content type 'application/x-gzip' length 3857500 bytes (3.7 MB)\n","==================================================\n","downloaded 3.7 MB\n","\n","trying URL 'https://cran.uni-muenster.de/src/contrib/lavaan_0.6-19.tar.gz'\n","Content type 'application/x-gzip' length 948608 bytes (926 KB)\n","==================================================\n","downloaded 926 KB\n","\n","trying URL 'https://cran.uni-muenster.de/src/contrib/semPlot_1.1.6.tar.gz'\n","Content type 'application/x-gzip' length 75629 bytes (73 KB)\n","==================================================\n","downloaded 73 KB\n","\n","trying URL 'https://cran.uni-muenster.de/src/contrib/psych_2.4.12.tar.gz'\n","Content type 'application/x-gzip' length 1310489 bytes (1.2 MB)\n","==================================================\n","downloaded 1.2 MB\n","\n","ERROR: failed to lock directory ‘/usr/local/lib/R/site-library’ for modifying\n","Try removing ‘/usr/local/lib/R/site-library/00LOCK-lme4’\n","ERROR: failed to lock directory ‘/usr/local/lib/R/site-library’ for modifying\n","Try removing ‘/usr/local/lib/R/site-library/00LOCK-OpenMx’\n","* installing *source* package ‘lavaan’ ...\n","** package ‘lavaan’ successfully unpacked and MD5 sums checked\n","** using staged installation\n","** R\n","** data\n","*** moving datasets to lazyload DB\n","** inst\n","** byte-compile and prepare package for lazy loading\n","** help\n","*** installing help indices\n","** building package indices\n","** testing if installed package can be loaded from temporary location\n","** testing if installed package can be loaded from final location\n","** testing if installed package keeps a record of temporary installation path\n","* DONE (lavaan)\n","* installing *source* package ‘psych’ ...\n","** package ‘psych’ successfully unpacked and MD5 sums checked\n","** using staged installation\n","** R\n","** data\n","*** moving datasets to lazyload DB\n","** inst\n","** byte-compile and prepare package for lazy loading\n","** help\n","*** installing help indices\n","** building package indices\n","** installing vignettes\n","** testing if installed package can be loaded from temporary location\n","** testing if installed package can be loaded from final location\n","** testing if installed package keeps a record of temporary installation path\n","* DONE (psych)\n","ERROR: dependency ‘lme4’ is not available for package ‘arm’\n","* removing ‘/usr/local/lib/R/site-library/arm’\n","ERROR: dependency ‘lme4’ is not available for package ‘rockchalk’\n","* removing ‘/usr/local/lib/R/site-library/rockchalk’\n","ERROR: dependency ‘arm’ is not available for package ‘mi’\n","* removing ‘/usr/local/lib/R/site-library/mi’\n","ERROR: dependency ‘mi’ is not available for package ‘sem’\n","* removing ‘/usr/local/lib/R/site-library/sem’\n","ERROR: dependencies ‘sem’, ‘rockchalk’, ‘OpenMx’ are not available for package ‘semPlot’\n","* removing ‘/usr/local/lib/R/site-library/semPlot’\n","\n","The downloaded source packages are in\n","\t‘/tmp/RtmpvBsKMs/downloaded_packages’\n","Warning messages:\n","1: In install.packages(c(\"lavaan\", \"semPlot\", \"psych\"), repos = \"https://cran.uni-muenster.de\",  :\n","  installation of package ‘lme4’ had non-zero exit status\n","2: In install.packages(c(\"lavaan\", \"semPlot\", \"psych\"), repos = \"https://cran.uni-muenster.de\",  :\n","  installation of package ‘OpenMx’ had non-zero exit status\n","3: In install.packages(c(\"lavaan\", \"semPlot\", \"psych\"), repos = \"https://cran.uni-muenster.de\",  :\n","  installation of package ‘arm’ had non-zero exit status\n","4: In install.packages(c(\"lavaan\", \"semPlot\", \"psych\"), repos = \"https://cran.uni-muenster.de\",  :\n","  installation of package ‘rockchalk’ had non-zero exit status\n","5: In install.packages(c(\"lavaan\", \"semPlot\", \"psych\"), repos = \"https://cran.uni-muenster.de\",  :\n","  installation of package ‘mi’ had non-zero exit status\n","6: In install.packages(c(\"lavaan\", \"semPlot\", \"psych\"), repos = \"https://cran.uni-muenster.de\",  :\n","  installation of package ‘sem’ had non-zero exit status\n","7: In install.packages(c(\"lavaan\", \"semPlot\", \"psych\"), repos = \"https://cran.uni-muenster.de\",  :\n","  installation of package ‘semPlot’ had non-zero exit status\n","> \n","> \n","Requirement already satisfied: rpy2==3.5.17 in /usr/local/lib/python3.11/dist-packages (3.5.17)\n","Requirement already satisfied: cffi>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from rpy2==3.5.17) (1.17.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from rpy2==3.5.17) (3.1.6)\n","Requirement already satisfied: tzlocal in /usr/local/lib/python3.11/dist-packages (from rpy2==3.5.17) (5.3.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.15.1->rpy2==3.5.17) (2.22)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->rpy2==3.5.17) (3.0.2)\n"]}],"source":["!R -e \"install.packages(c('lavaan','semPlot', 'psych'), repos='https://cran.uni-muenster.de', quiet=TRUE)\"\n","!pip install rpy2==3.5.17"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3910,"status":"ok","timestamp":1741814039859,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"},"user_tz":-60},"id":"E57mXg5eZssL","outputId":"6eb3de60-0b03-4742-da4c-f68d54649471"},"outputs":[{"output_type":"stream","name":"stdout","text":["The rpy2.ipython extension is already loaded. To reload it, use:\n","  %reload_ext rpy2.ipython\n"]},{"output_type":"execute_result","data":{"text/plain":["rpy2.robjects.packages.Package as a <module 'stats'>"]},"metadata":{},"execution_count":18}],"source":["# General imports\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Rpy2 imports\n","from rpy2 import robjects as ro\n","from rpy2.robjects import pandas2ri, numpy2ri\n","from rpy2.robjects.packages import importr\n","\n","# Automatic conversion of arrays and dataframes\n","pandas2ri.activate()\n","numpy2ri.activate()\n","\n","# Set random seed for reproducibility\n","ro.r('set.seed(123)')\n","\n","# Ipython extenrsion for magix plotting\n","%load_ext rpy2.ipython\n","\n","# R imports\n","importr('base')\n","importr('lavaan')\n","#importr('semPlot') # CHECK: Does not work\n","importr('psych')\n","importr('stats')"]},{"cell_type":"markdown","source":["## 1. Preparation\n","Welcome to today's seminar on measurement models applied to quantitative\n","\n","### Load, prepare and inspect the dataset\n","\n","#### **The dataset**\n","\n","For this exercise we use a dataset from Lischetzke (2003). The construct we want to measure is **emotional clarity** by means of reaction times (RT) on a mood intensity scale. It is assumed that the faster people assess their mood, the greater the emotional clarity.\n","\n","#### **Load and inspect the full data set**\n"],"metadata":{"id":"HFAtMBiOL8ZN"}},{"cell_type":"code","source":["file_name = \"Data_EmotionalClarity.dat\"\n","dat = pd.read_csv(file_name, sep=\"\\t\")\n","print(dat.head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wZWFF8nMMFFQ","executionInfo":{"status":"ok","timestamp":1741813821624,"user_tz":-60,"elapsed":5,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"7ba8c27e-c97a-4746-b793-481e91ab21cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["   sex    item_1    item_2    item_3    item_4    item_5    item_6\n","0    1  1.463255  1.739589  1.384292  1.568408  1.457452  1.628260\n","1    1  1.689358  1.789256  1.771557  1.696533  1.395997  1.842294\n","2    0  1.300736  1.492455  1.347294  1.178347  1.784903  1.221125\n","3    0  1.588419  1.459545  1.300736  1.278152  1.145496  1.446213\n","4    0  1.182953  0.914289  0.997686  1.357895  0.875052  1.232852\n"]}]},{"cell_type":"markdown","source":["#### **Extract items 1 to 6 for the analysis**"],"metadata":{"id":"_RpFxasHMFZ6"}},{"cell_type":"code","source":["dat2 = dat.iloc[:, 1:7]\n","print(dat2.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7yW-as2CMLYc","executionInfo":{"status":"ok","timestamp":1741813866286,"user_tz":-60,"elapsed":13,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"660029ab-fb79-48b5-c000-89297bab8534"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["     item_1    item_2    item_3    item_4    item_5    item_6\n","0  1.463255  1.739589  1.384292  1.568408  1.457452  1.628260\n","1  1.689358  1.789256  1.771557  1.696533  1.395997  1.842294\n","2  1.300736  1.492455  1.347294  1.178347  1.784903  1.221125\n","3  1.588419  1.459545  1.300736  1.278152  1.145496  1.446213\n","4  1.182953  0.914289  0.997686  1.357895  0.875052  1.232852\n"]}]},{"cell_type":"markdown","source":["#### **Compute and plot the covariance/correlation matrix**\n","Use the following snippet to compute and plot the covariance/correlation matrix."],"metadata":{"id":"73S57WurM3Ar"}},{"cell_type":"code","source":["print(dat2.cov())  # Covariance matrix\n","print(dat2.corr())  # Correlation matrix\n","\n","# Plot correlation matrix\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(dat2.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n","plt.title(\"Correlation Matrix\")\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":803},"id":"0h0cO1LeMvVu","executionInfo":{"status":"ok","timestamp":1741814048809,"user_tz":-60,"elapsed":548,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"5db00acd-7857-4117-cfe8-33f2d69f5ec3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["          item_1    item_2    item_3    item_4    item_5    item_6\n","item_1  0.128924  0.063721  0.063875  0.066945  0.044849  0.056841\n","item_2  0.063721  0.136013  0.066922  0.069953  0.065735  0.056597\n","item_3  0.063875  0.066922  0.153899  0.081548  0.065970  0.065104\n","item_4  0.066945  0.069953  0.081548  0.166135  0.072298  0.075799\n","item_5  0.044849  0.065735  0.065970  0.072298  0.142077  0.054706\n","item_6  0.056841  0.056597  0.065104  0.075799  0.054706  0.146929\n","          item_1    item_2    item_3    item_4    item_5    item_6\n","item_1  1.000000  0.481200  0.453468  0.457424  0.331381  0.412995\n","item_2  0.481200  1.000000  0.462554  0.465358  0.472874  0.400359\n","item_3  0.453468  0.462554  1.000000  0.509996  0.446138  0.432950\n","item_4  0.457424  0.465358  0.509996  1.000000  0.470581  0.485157\n","item_5  0.331381  0.472874  0.446138  0.470581  1.000000  0.378636\n","item_6  0.412995  0.400359  0.432950  0.485157  0.378636  1.000000\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 800x600 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["#### **Compute the mean response vector**\n","Try this by yourself before exploring the solution."],"metadata":{"id":"51rhNMUDMKnW"}},{"cell_type":"code","source":["means = dat2.apply(lambda x: x.mean())  # Column-wise mean\n","print(means)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MuNcIGCvMPXt","executionInfo":{"status":"ok","timestamp":1741814069614,"user_tz":-60,"elapsed":41,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"dbd49943-10a2-418e-bab3-7a869a53869b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["item_1    1.504005\n","item_2    1.422903\n","item_3    1.392156\n","item_4    1.304696\n","item_5    1.346359\n","item_6    1.305712\n","dtype: float64\n"]}]},{"cell_type":"markdown","source":["#### **Compute the item SDs and Variances**\n","In this code chunk lets now calculate the SDs and variances **for every item**.\n","Try using the apply as it was just explained above."],"metadata":{"id":"6K7OKkIXMNqC"}},{"cell_type":"code","source":["sds = dat2.apply(lambda x: x.std())  # Column-wise standard deviation\n","print(sds)\n","variances = dat2.apply(lambda x: x.var())  # Column-wise variance\n","print(variances)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fRvF3JsFMSJb","executionInfo":{"status":"ok","timestamp":1741814132784,"user_tz":-60,"elapsed":50,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"761dfc1d-4205-44db-f964-864fb2fd5815"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["item_1    0.359060\n","item_2    0.368799\n","item_3    0.392299\n","item_4    0.407597\n","item_5    0.376931\n","item_6    0.383313\n","dtype: float64\n","item_1    0.128924\n","item_2    0.136013\n","item_3    0.153899\n","item_4    0.166135\n","item_5    0.142077\n","item_6    0.146929\n","dtype: float64\n"]}]},{"cell_type":"markdown","source":["## 2. Tau Congeneric measurement model\n","We will now start testing the measurement models that were covered in lecture section of this course two weeks ago.\n","\n","The **Tau Congeneric** measurement model is the least restrictive one out of the measurement models that we will use today. It assumes that:\n","\n","* items differ in their difficulty\n","* items differ in their discrimination power\n","* items are differently reliable  \n","\n","We therefore get an estimate for the loading (`Latent Variables` section), for the intercept (`Intecepts` section) and for the errors (`Variances` section) respectively.\n","\n","### Fit the model\n","We are now going to define the model using `lavaan` syntax."],"metadata":{"id":"qUgh-zyFMRpC"}},{"cell_type":"code","source":["# Put data into R\n","ro.globalenv['dat2'] = dat2\n","# Specify the model\n","ro.r(\"mtc <- 'eta =~ item_1 + item_2 + item_3 + item_4 + item_5 + item_6'\")\n","# Fit the model\n","ro.r('fitmtc <- sem(mtc, data=dat2, meanstructure=TRUE, estimator=\"ML\")')\n","# Print the output of the model for interpretation\n","summary_fitmtc = ro.r(\"summary(fitmtc, fit.measures=TRUE, standardized=TRUE)\")\n","print(summary_fitmtc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YJN8o0gcNsEi","executionInfo":{"status":"ok","timestamp":1741814750617,"user_tz":-60,"elapsed":143,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"02c0e589-876d-40be-f374-459dc69ce3cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["lavaan 0.6-19 ended normally after 38 iterations\n","\n","  Estimator                                         ML\n","  Optimization method                           NLMINB\n","  Number of model parameters                        18\n","\n","  Number of observations                           238\n","\n","Model Test User Model:\n","                                                      \n","  Test statistic                                 9.568\n","  Degrees of freedom                                 9\n","  P-value (Chi-square)                           0.387\n","\n","Model Test Baseline Model:\n","\n","  Test statistic                               435.847\n","  Degrees of freedom                                15\n","  P-value                                        0.000\n","\n","User Model versus Baseline Model:\n","\n","  Comparative Fit Index (CFI)                    0.999\n","  Tucker-Lewis Index (TLI)                       0.998\n","\n","Loglikelihood and Information Criteria:\n","\n","  Loglikelihood user model (H0)               -432.180\n","  Loglikelihood unrestricted model (H1)       -427.396\n","                                                      \n","  Akaike (AIC)                                 900.360\n","  Bayesian (BIC)                               962.861\n","  Sample-size adjusted Bayesian (SABIC)        905.806\n","\n","Root Mean Square Error of Approximation:\n","\n","  RMSEA                                          0.016\n","  90 Percent confidence interval - lower         0.000\n","  90 Percent confidence interval - upper         0.076\n","  P-value H_0: RMSEA <= 0.050                    0.763\n","  P-value H_0: RMSEA >= 0.080                    0.036\n","\n","Standardized Root Mean Square Residual:\n","\n","  SRMR                                           0.021\n","\n","Parameter Estimates:\n","\n","  Standard errors                             Standard\n","  Information                                 Expected\n","  Information saturated (h1) model          Structured\n","\n","Latent Variables:\n","                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n","  eta =~                                                                \n","    item_1            1.000                               0.229    0.638\n","    item_2            1.098    0.131    8.404    0.000    0.251    0.682\n","    item_3            1.194    0.140    8.535    0.000    0.273    0.697\n","    item_4            1.294    0.147    8.790    0.000    0.296    0.728\n","    item_5            1.032    0.131    7.886    0.000    0.236    0.628\n","    item_6            1.049    0.133    7.886    0.000    0.240    0.628\n","\n","Intercepts:\n","                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n","   .item_1            1.504    0.023   64.757    0.000    1.504    4.198\n","   .item_2            1.423    0.024   59.647    0.000    1.423    3.866\n","   .item_3            1.392    0.025   54.862    0.000    1.392    3.556\n","   .item_4            1.305    0.026   49.486    0.000    1.305    3.208\n","   .item_5            1.346    0.024   55.221    0.000    1.346    3.579\n","   .item_6            1.306    0.025   52.662    0.000    1.306    3.414\n","\n","Variances:\n","                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n","   .item_1            0.076    0.008    9.363    0.000    0.076    0.593\n","   .item_2            0.072    0.008    8.941    0.000    0.072    0.534\n","   .item_3            0.079    0.009    8.770    0.000    0.079    0.514\n","   .item_4            0.078    0.009    8.362    0.000    0.078    0.471\n","   .item_5            0.086    0.009    9.449    0.000    0.086    0.606\n","   .item_6            0.089    0.009    9.449    0.000    0.089    0.606\n","    eta               0.052    0.010    5.051    0.000    1.000    1.000\n","\n","\n"]}]},{"cell_type":"markdown","source":["#### **Model fit**\n","\n","Before we look at the model parameters, lets first look at the model fit indices (remember them ;) ?).  \n","The insignificant p-value for the $\\chi^2$ test indicates that our model implied correlation matrix doesn't deviate significantly from the data implied correlation matrix, suggesting a good fit. Furthermore, the CFI and TLI are > .95, also indicating a good fit. AIC and BIC can't be interpreted individually but will be later used for comparing models (see below). Lastly, the RMSEA and SRMR are also < .08, also suggesting a good fit. In summary, all indices suggest that the models fits our data well.  \n","As a reminder - the usual limit value / criteria for the various fit indices:\n","\n","* $\\chi^2$ Test: Insignificance (p-value) suggests good fit, larger $\\chi^2$ values (test statistics) indicate worse fit\n","* CFI & TLI: Values closer to 1 indicate good fit, > .95 desirable\n","* AIC & BIC: Can't be interpreted individually! Only for model comparison\n","* RMSEA & SRMR: Smaller values indicate better fit, < .08 desirable\n","\n","#### **Latent variables section**\n","\n","Increasing loadings can be interpreted as the respective item having a higher discrimination power.\n","For example, `item_1` has a loading of 1.098 while `item_4` has a loading of 1.294, meaning that the same increase in the latent variable (i.e. the trait we\n","measure) results in a larger difference in `item_4` compared to `item_1`. Graphically this is represented by `item_4` having a steeper slope. You might notice that the loading are quite similar across the items, keep this in mind for later.\n","\n","#### **Intercepts section**\n","\n","The intercepts can be used to interpret the difficulty of the item. Here, bigger values indicate that an item is **more** difficult. However, watch out: The interpretation can differ in other cases. Here, larger intercepts relate to larger reaction times, meaning, according to the theory, the mood which is assessed with this item is 'less emotionally clear'. On the other hand, if we would like to assess intelligence by the percentage of correct answers in a test, a larger intercept would mean that even individuals with 0 (or average, if centered) intelligence would end up with a large percentage of correct answers, meaning our item is actually to **easy**.\n","(Technically, you can always say that an item associated with a larger intercept is more difficult. However, the explicit interpretation can differ).\n","\n","#### **Variances section**\n","\n","The Variances refer to the reliability of the items. Speaking in a 'CFA-Language', they represent the residuals (errors) associated with the items. In the last row, the variance of the latent variable is shown.\n","\n","### Try it yourself\n","Now try fitting a new model excluding item 2 and item 3, how does the fit change? Can you spot any difference between the two models?"],"metadata":{"id":"NUUvryQ0QF8j"}},{"cell_type":"code","source":["# Remove Items 2 and 3\n","dat3 = dat2.drop(columns=['item_2', 'item_3'])\n","print(dat3.head())\n","# Put data into R\n","ro.globalenv['dat3'] = dat3\n","# Specify the model\n","ro.r(\"mtc2 <- 'eta =~ item_1 + item_4 + item_5 + item_6'\")\n","# Fit the model\n","ro.r('fitmtc2 <- sem(mtc2, data=dat3, meanstructure=TRUE, estimator=\"ML\")')\n","# Print the output of the model for interpretation\n","summary_fitmtc2 = ro.r(\"summary(fitmtc2, fit.measures=TRUE, standardized=TRUE)\")\n","print(summary_fitmtc2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1GWj0r_8QGp8","executionInfo":{"status":"ok","timestamp":1741814902733,"user_tz":-60,"elapsed":167,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"0bffe99e-d07c-41e4-8c6a-294b33a794a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["     item_1    item_4    item_5    item_6\n","0  1.463255  1.568408  1.457452  1.628260\n","1  1.689358  1.696533  1.395997  1.842294\n","2  1.300736  1.178347  1.784903  1.221125\n","3  1.588419  1.278152  1.145496  1.446213\n","4  1.182953  1.357895  0.875052  1.232852\n","lavaan 0.6-19 ended normally after 32 iterations\n","\n","  Estimator                                         ML\n","  Optimization method                           NLMINB\n","  Number of model parameters                        12\n","\n","  Number of observations                           238\n","\n","Model Test User Model:\n","                                                      \n","  Test statistic                                 1.089\n","  Degrees of freedom                                 2\n","  P-value (Chi-square)                           0.580\n","\n","Model Test Baseline Model:\n","\n","  Test statistic                               206.009\n","  Degrees of freedom                                 6\n","  P-value                                        0.000\n","\n","User Model versus Baseline Model:\n","\n","  Comparative Fit Index (CFI)                    1.000\n","  Tucker-Lewis Index (TLI)                       1.014\n","\n","Loglikelihood and Information Criteria:\n","\n","  Loglikelihood user model (H0)               -328.557\n","  Loglikelihood unrestricted model (H1)       -328.012\n","                                                      \n","  Akaike (AIC)                                 681.113\n","  Bayesian (BIC)                               722.781\n","  Sample-size adjusted Bayesian (SABIC)        684.744\n","\n","Root Mean Square Error of Approximation:\n","\n","  RMSEA                                          0.000\n","  90 Percent confidence interval - lower         0.000\n","  90 Percent confidence interval - upper         0.108\n","  P-value H_0: RMSEA <= 0.050                    0.732\n","  P-value H_0: RMSEA >= 0.080                    0.131\n","\n","Standardized Root Mean Square Residual:\n","\n","  SRMR                                           0.011\n","\n","Parameter Estimates:\n","\n","  Standard errors                             Standard\n","  Information                                 Expected\n","  Information saturated (h1) model          Structured\n","\n","Latent Variables:\n","                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n","  eta =~                                                                \n","    item_1            1.000                               0.215    0.600\n","    item_4            1.451    0.195    7.426    0.000    0.312    0.767\n","    item_5            1.038    0.155    6.701    0.000    0.223    0.594\n","    item_6            1.149    0.163    7.061    0.000    0.247    0.646\n","\n","Intercepts:\n","                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n","   .item_1            1.504    0.023   64.757    0.000    1.504    4.198\n","   .item_4            1.305    0.026   49.486    0.000    1.305    3.208\n","   .item_5            1.346    0.024   55.221    0.000    1.346    3.579\n","   .item_6            1.306    0.025   52.662    0.000    1.306    3.414\n","\n","Variances:\n","                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n","   .item_1            0.082    0.009    8.894    0.000    0.082    0.640\n","   .item_4            0.068    0.012    5.832    0.000    0.068    0.412\n","   .item_5            0.092    0.010    8.967    0.000    0.092    0.648\n","   .item_6            0.085    0.010    8.289    0.000    0.085    0.583\n","    eta               0.046    0.011    4.401    0.000    1.000    1.000\n","\n","\n"]}]},{"cell_type":"markdown","source":["## 3. Essentially tau-equivalent model\n","\n","The **Essentially tau-equivalent** measurement model is also quite flexible but it has one more restriction compared to the **Tau Congeneric** measurement model. It assumes that\n","\n","* items differ in their difficulty\n","* items **are equivalent in their discrimination power**\n","* items are differently reliable  \n","\n","We therefore get an estimate for the intercepts (`Intecepts` section) and for the errors (`Variances` section). Note that we also get a `Latent Variables` section again, however, you will have to fix all the loadings to 1.\n","\n","### Fit the model"],"metadata":{"id":"sOA9dzgpQn83"}},{"cell_type":"code","source":["# Specify the model\n","ro.r(\"mete <<-'eta=~ item_1 + 1*item_2 + 1*item_3 + 1*item_4 + 1*item_5 + 1*item_6'\")\n","# Fit the model\n","ro.r('fitmete <- sem(mete, data=dat2, meanstructure=TRUE, estimator=\"ML\")')\n","# Print the output of the model for interpretation\n","summary_fitmete = ro.r(\"summary(fitmete, fit.measures=TRUE, standardized=TRUE)\")\n","print(summary_fitmete)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"acrAbRVuQoom","executionInfo":{"status":"ok","timestamp":1741815040831,"user_tz":-60,"elapsed":146,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"164503cb-a615-4953-a214-be479da8c779"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["lavaan 0.6-19 ended normally after 12 iterations\n","\n","  Estimator                                         ML\n","  Optimization method                           NLMINB\n","  Number of model parameters                        13\n","\n","  Number of observations                           238\n","\n","Model Test User Model:\n","                                                      \n","  Test statistic                                16.949\n","  Degrees of freedom                                14\n","  P-value (Chi-square)                           0.259\n","\n","Model Test Baseline Model:\n","\n","  Test statistic                               435.847\n","  Degrees of freedom                                15\n","  P-value                                        0.000\n","\n","User Model versus Baseline Model:\n","\n","  Comparative Fit Index (CFI)                    0.993\n","  Tucker-Lewis Index (TLI)                       0.992\n","\n","Loglikelihood and Information Criteria:\n","\n","  Loglikelihood user model (H0)               -435.870\n","  Loglikelihood unrestricted model (H1)       -427.396\n","                                                      \n","  Akaike (AIC)                                 897.740\n","  Bayesian (BIC)                               942.880\n","  Sample-size adjusted Bayesian (SABIC)        901.674\n","\n","Root Mean Square Error of Approximation:\n","\n","  RMSEA                                          0.030\n","  90 Percent confidence interval - lower         0.000\n","  90 Percent confidence interval - upper         0.073\n","  P-value H_0: RMSEA <= 0.050                    0.737\n","  P-value H_0: RMSEA >= 0.080                    0.023\n","\n","Standardized Root Mean Square Residual:\n","\n","  SRMR                                           0.053\n","\n","Parameter Estimates:\n","\n","  Standard errors                             Standard\n","  Information                                 Expected\n","  Information saturated (h1) model          Structured\n","\n","Latent Variables:\n","                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n","  eta =~                                                                \n","    item_1            1.000                               0.253    0.682\n","    item_2            1.000                               0.253    0.689\n","    item_3            1.000                               0.253    0.664\n","    item_4            1.000                               0.253    0.656\n","    item_5            1.000                               0.253    0.657\n","    item_6            1.000                               0.253    0.650\n","\n","Intercepts:\n","                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n","   .item_1            1.504    0.024   62.432    0.000    1.504    4.047\n","   .item_2            1.423    0.024   59.697    0.000    1.423    3.870\n","   .item_3            1.392    0.025   56.265    0.000    1.392    3.647\n","   .item_4            1.305    0.025   52.077    0.000    1.305    3.376\n","   .item_5            1.346    0.025   53.815    0.000    1.346    3.488\n","   .item_6            1.306    0.025   51.677    0.000    1.306    3.350\n","\n","Variances:\n","                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n","   .item_1            0.074    0.008    9.254    0.000    0.074    0.535\n","   .item_2            0.071    0.008    9.186    0.000    0.071    0.525\n","   .item_3            0.081    0.009    9.410    0.000    0.081    0.559\n","   .item_4            0.085    0.009    9.475    0.000    0.085    0.570\n","   .item_5            0.085    0.009    9.468    0.000    0.085    0.569\n","   .item_6            0.088    0.009    9.518    0.000    0.088    0.577\n","    eta               0.064    0.007    9.004    0.000    1.000    1.000\n","\n","\n"]}]},{"cell_type":"markdown","source":["You can see that the output looks very similar to the one from the **Tau Congeneric** measurement model. The interpretation of the intercepts (`Intecepts` section) and for the errors (`Variances` section) is the same as before. The only difference is that the loadings (`Latent Variables` section) are all fixed to one, meaning that we assume that all items have the same discriminatory power. Graphically speaking, this means that the slopes of the items are equivalent. The interpretation of the fit indices is analogous to the **Tau Congeneric** measurement model (see above).\n","\n","### Compare model fit\n","\n","Next, lets compare the models we just fitted."],"metadata":{"id":"eGSdiSYCRKby"}},{"cell_type":"code","source":["# Perform anova and print indexes\n","anova_mete_mtc = ro.r(\"anova(fitmete, fitmtc)\")\n","lavTestLRT_mete_mtc = ro.r(\"lavTestLRT(fitmete, fitmtc)\")\n","print(anova_mete_mtc)\n","print(lavTestLRT_mete_mtc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L5BmvH6URK0Z","executionInfo":{"status":"ok","timestamp":1741815273084,"user_tz":-60,"elapsed":39,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"c2ab28ce-ff2b-446c-b94d-220f2953dc3d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Chi-Squared Difference Test\n","\n","        Df    AIC    BIC   Chisq Chisq diff    RMSEA Df diff Pr(>Chisq)\n","fitmtc   9 900.36 962.86  9.5683                                       \n","fitmete 14 897.74 942.88 16.9488     7.3805 0.044726       5     0.1938\n","\n","\n","Chi-Squared Difference Test\n","\n","        Df    AIC    BIC   Chisq Chisq diff    RMSEA Df diff Pr(>Chisq)\n","fitmtc   9 900.36 962.86  9.5683                                       \n","fitmete 14 897.74 942.88 16.9488     7.3805 0.044726       5     0.1938\n","\n"]}]},{"cell_type":"markdown","source":["According to the BIC and AIC the more restricted **Essentially tau-equivalent** model has a better model fit compared to the **Tau Congeneric** measurement model (as lower values for AIC and BIC indicate better model fit). The $\\chi^2$ Test however suggests that there are no significant differences in model fit as indicated by p > .05. This result is not too surprising as we already saw quite similar loading estimates across items in the **Tau Congeneric** measurement model (see above). Therefore, restricting the loadings to equivalence isn't too much of a deviation from the **Tau Congeneric** measurement model (which does not restrict the loadings), resulting in a insignificant difference in model fit.\n","\n","## 4. Tau-equivalent model\n","\n","The **Tau-equivalent** measurement model has one more restriction compared to the **Essentially tau-equivalent** model. It assumes that\n","\n","* items **are equivalent in their difficulty**\n","* items **are equivalent in their discrimination power**\n","* items are differently reliable  \n","\n","We therefore only get an estimate for the errors (`Variances` section). Note that we also get a `Latent Variables` section and\n","a `Intecepts` section again, however, you can see that all the loadings and intercepts are fixed.\n","\n","### Fit the model and a quick rpy2 hint\n","\n","Using `rpy2` to Define Multi-Line Lavaan Models in R  \n","\n","When working with `rpy2` in Python to execute R commands, multi-line strings must be formatted correctly. R's **lavaan** package requires structured model definitions, but Python's `rpy2` only accepts single-line strings. To maintain readability and correctness, **`\\n`** is used to preserve line breaks.\n","\n","### **Example: Defining a Latent Variable Model in R**  \n","\n","```python\n","ro.r(\"mte <<- 'eta =~ item_1 + 1*item_2 + 1*item_3 + 1*item_4 + 1*item_5 + 1*item_6\\n\"\n","      \"item_1 ~ a*1\\n\"\n","      \"item_2 ~ a*1\\n\"\n","      \"item_3 ~ a*1\\n\"\n","      \"item_4 ~ a*1\\n\"\n","      \"item_5 ~ a*1\\n\"\n","      \"item_6 ~ a*1'\")\n"],"metadata":{"id":"iIfWYxI7SF_c"}},{"cell_type":"code","source":["# Specify the model\n","ro.r(\"mte <<- 'eta =~ item_1 + 1*item_2 + 1*item_3 + 1*item_4 + 1*item_5 + 1*item_6\\n\"\n","      \"item_1 ~ a*1\\n\"\n","      \"item_2 ~ a*1\\n\"\n","      \"item_3 ~ a*1\\n\"\n","      \"item_4 ~ a*1\\n\"\n","      \"item_5 ~ a*1\\n\"\n","      \"item_6 ~ a*1'\")\n","\n","# Fit the model\n","ro.r('fitmte <- sem(mte, data=dat2, meanstructure=TRUE, estimator=\"ML\")')\n","# Print the output of the model for interpretation\n","summary_fitmte = ro.r(\"summary(fitmte, fit.measures=TRUE, standardized=TRUE)\")\n","print(summary_fitmte)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mE5U94EZSNd0","executionInfo":{"status":"ok","timestamp":1741815563045,"user_tz":-60,"elapsed":156,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"ff56bda6-c9a9-4362-9cbf-395572e1d482"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["lavaan 0.6-19 ended normally after 13 iterations\n","\n","  Estimator                                         ML\n","  Optimization method                           NLMINB\n","  Number of model parameters                        13\n","  Number of equality constraints                     5\n","\n","  Number of observations                           238\n","\n","Model Test User Model:\n","                                                      \n","  Test statistic                               100.116\n","  Degrees of freedom                                19\n","  P-value (Chi-square)                           0.000\n","\n","Model Test Baseline Model:\n","\n","  Test statistic                               435.847\n","  Degrees of freedom                                15\n","  P-value                                        0.000\n","\n","User Model versus Baseline Model:\n","\n","  Comparative Fit Index (CFI)                    0.807\n","  Tucker-Lewis Index (TLI)                       0.848\n","\n","Loglikelihood and Information Criteria:\n","\n","  Loglikelihood user model (H0)               -477.454\n","  Loglikelihood unrestricted model (H1)       -427.396\n","                                                      \n","  Akaike (AIC)                                 970.908\n","  Bayesian (BIC)                               998.686\n","  Sample-size adjusted Bayesian (SABIC)        973.329\n","\n","Root Mean Square Error of Approximation:\n","\n","  RMSEA                                          0.134\n","  90 Percent confidence interval - lower         0.109\n","  90 Percent confidence interval - upper         0.160\n","  P-value H_0: RMSEA <= 0.050                    0.000\n","  P-value H_0: RMSEA >= 0.080                    1.000\n","\n","Standardized Root Mean Square Residual:\n","\n","  SRMR                                           0.111\n","\n","Parameter Estimates:\n","\n","  Standard errors                             Standard\n","  Information                                 Expected\n","  Information saturated (h1) model          Structured\n","\n","Latent Variables:\n","                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n","  eta =~                                                                \n","    item_1            1.000                               0.252    0.637\n","    item_2            1.000                               0.252    0.683\n","    item_3            1.000                               0.252    0.663\n","    item_4            1.000                               0.252    0.639\n","    item_5            1.000                               0.252    0.655\n","    item_6            1.000                               0.252    0.634\n","\n","Intercepts:\n","                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n","   .item_1     (a)    1.381    0.018   76.284    0.000    1.381    3.485\n","   .item_2     (a)    1.381    0.018   76.284    0.000    1.381    3.736\n","   .item_3     (a)    1.381    0.018   76.284    0.000    1.381    3.630\n","   .item_4     (a)    1.381    0.018   76.284    0.000    1.381    3.496\n","   .item_5     (a)    1.381    0.018   76.284    0.000    1.381    3.585\n","   .item_6     (a)    1.381    0.018   76.284    0.000    1.381    3.471\n","\n","Variances:\n","                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n","   .item_1            0.093    0.010    9.529    0.000    0.093    0.594\n","   .item_2            0.073    0.008    9.138    0.000    0.073    0.534\n","   .item_3            0.081    0.009    9.318    0.000    0.081    0.560\n","   .item_4            0.092    0.010    9.513    0.000    0.092    0.592\n","   .item_5            0.085    0.009    9.387    0.000    0.085    0.571\n","   .item_6            0.095    0.010    9.548    0.000    0.095    0.598\n","    eta               0.064    0.007    8.880    0.000    1.000    1.000\n","\n","\n"]}]},{"cell_type":"markdown","source":["Again, the output looks very similar to the previous ones. The interpretation also is equivalent to before. The only difference is that the loadings (`Latent Variables` section) and the intercept (`Intercepts` section) are fixed, meaning that we assume that all items have the same discriminatory power and the same difficulty. Graphically speaking, this means that the slopes and the intercepts of the items are equivalent. The interpretation of the fit indices is analogous to the **Tau Congeneric** measurement model (see above).\n","\n","### Compare model fit\n","\n","As before, we can use the `anova()` function to compare the model fits."],"metadata":{"id":"6EypQdsxTJfk"}},{"cell_type":"code","source":["# Perform anova and print indexes\n","anova_mete_mte = ro.r(\"anova(fitmete, fitmte)\")\n","print(anova_mete_mte)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3QU6P40-TJ3e","executionInfo":{"status":"ok","timestamp":1741816178408,"user_tz":-60,"elapsed":9,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"d39605ad-af29-4408-fadc-d1e4495767e2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Chi-Squared Difference Test\n","\n","        Df    AIC    BIC   Chisq Chisq diff   RMSEA Df diff Pr(>Chisq)    \n","fitmete 14 897.74 942.88  16.949                                          \n","fitmte  19 970.91 998.69 100.116     83.168 0.25629       5  < 2.2e-16 ***\n","---\n","Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n","\n"]}]},{"cell_type":"markdown","source":["In this comparison, the more restricted Tau-equivalent model has significantly worse fit compared to the Essentially tau-equivalent model as indicated by the significant differences in $\\chi^2$. Also AIC and BIC favor the more flexible model.\n","\n","## 5. Essentially tau-parallel measurement model\n","\n","The **Essentially tau-parallel** measurement model looses one restriction compared to the Tau-equivalent model by letting the intercepts vary. However, it restricts the items to have equivalent reliability. It assumes that\n","\n","* items **differ in their difficulty**\n","* items are equivalent in their discrimination power\n","* items are **equivalently reliable**  \n","\n","We therefore only get estimates for the difficulty of the items (`Intercepts` section). Discrimination power (`Latent variables` section) and Reliability (`Variances` section) are fixed across items.\n","\n","### Fit the model"],"metadata":{"id":"Auo1t_whTMHB"}},{"cell_type":"code","source":["# Specify the model\n","ro.r(\"metp <<- 'eta =~ item_1 + 1*item_2 + 1*item_3 + 1*item_4 + 1*item_5 + 1*item_6\\n\"\n","      \"item_1 ~~ b*item_1\\n\"\n","      \"item_2 ~~ b*item_2\\n\"\n","      \"item_3 ~~ b*item_3\\n\"\n","      \"item_4 ~~ b*item_4\\n\"\n","      \"item_5 ~~ b*item_5\\n\"\n","      \"item_6 ~~ b*item_6'\")\n","\n","# Fit the model\n","ro.r('fitmetp <- sem(metp, data=dat2, meanstructure=TRUE, estimator=\"ML\")')\n","# Print the output of the model for interpretation\n","summary_fitmetp = ro.r(\"summary(fitmetp, fit.measures=TRUE, standardized=TRUE)\")\n","print(summary_fitmetp)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ojqOLGsVT7DD","executionInfo":{"status":"ok","timestamp":1741816049318,"user_tz":-60,"elapsed":159,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"a413e43d-f66d-4576-bb40-44727c2aabbb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["lavaan 0.6-19 ended normally after 13 iterations\n","\n","  Estimator                                         ML\n","  Optimization method                           NLMINB\n","  Number of model parameters                        13\n","  Number of equality constraints                     5\n","\n","  Number of observations                           238\n","\n","Model Test User Model:\n","                                                      \n","  Test statistic                                19.886\n","  Degrees of freedom                                19\n","  P-value (Chi-square)                           0.401\n","\n","Model Test Baseline Model:\n","\n","  Test statistic                               435.847\n","  Degrees of freedom                                15\n","  P-value                                        0.000\n","\n","User Model versus Baseline Model:\n","\n","  Comparative Fit Index (CFI)                    0.998\n","  Tucker-Lewis Index (TLI)                       0.998\n","\n","Loglikelihood and Information Criteria:\n","\n","  Loglikelihood user model (H0)               -437.339\n","  Loglikelihood unrestricted model (H1)       -427.396\n","                                                      \n","  Akaike (AIC)                                 890.677\n","  Bayesian (BIC)                               918.455\n","  Sample-size adjusted Bayesian (SABIC)        893.098\n","\n","Root Mean Square Error of Approximation:\n","\n","  RMSEA                                          0.014\n","  90 Percent confidence interval - lower         0.000\n","  90 Percent confidence interval - upper         0.059\n","  P-value H_0: RMSEA <= 0.050                    0.884\n","  P-value H_0: RMSEA >= 0.080                    0.003\n","\n","Standardized Root Mean Square Residual:\n","\n","  SRMR                                           0.059\n","\n","Parameter Estimates:\n","\n","  Standard errors                             Standard\n","  Information                                 Expected\n","  Information saturated (h1) model          Structured\n","\n","Latent Variables:\n","                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n","  eta =~                                                                \n","    item_1            1.000                               0.254    0.667\n","    item_2            1.000                               0.254    0.667\n","    item_3            1.000                               0.254    0.667\n","    item_4            1.000                               0.254    0.667\n","    item_5            1.000                               0.254    0.667\n","    item_6            1.000                               0.254    0.667\n","\n","Intercepts:\n","                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n","   .item_1            1.504    0.025   60.923    0.000    1.504    3.949\n","   .item_2            1.423    0.025   57.637    0.000    1.423    3.736\n","   .item_3            1.392    0.025   56.392    0.000    1.392    3.655\n","   .item_4            1.305    0.025   52.849    0.000    1.305    3.426\n","   .item_5            1.346    0.025   54.537    0.000    1.346    3.535\n","   .item_6            1.306    0.025   52.890    0.000    1.306    3.428\n","\n","Variances:\n","                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n","   .item_1     (b)    0.081    0.003   24.393    0.000    0.081    0.556\n","   .item_2     (b)    0.081    0.003   24.393    0.000    0.081    0.556\n","   .item_3     (b)    0.081    0.003   24.393    0.000    0.081    0.556\n","   .item_4     (b)    0.081    0.003   24.393    0.000    0.081    0.556\n","   .item_5     (b)    0.081    0.003   24.393    0.000    0.081    0.556\n","   .item_6     (b)    0.081    0.003   24.393    0.000    0.081    0.556\n","    eta               0.064    0.007    9.001    0.000    1.000    1.000\n","\n","\n"]}]},{"cell_type":"markdown","source":["In the output we see fixed parameters in the `Latent variables` section and in the `Variances` section. However, intercepts (i.e. item difficulties) are allowed to vary) as you can see in the `Intercepts` section. `item_1` has the highest difficulty (1.504) and `item_4`has the lowest difficulty (1.305). This means that an individual with a score of 0 for the latent variable (here: **emotional clarity**) (or a mean score if the latent variable is centered) scores the lowest on `item_4` and highest on `item_1`. The interpretation of the fit indices is analogous to the **Tau Congeneric** measurement model (see above).\n","\n","### Compare model fit\n","\n","As before, we can use the `anova()` function to compare the model fits."],"metadata":{"id":"IAf2aZ0XUZs2"}},{"cell_type":"code","source":["# Perform anova and print indexes\n","anova_mete_mept = ro.r(\"anova(fitmete, fitmetp)\")\n","print(anova_mete_mept)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2SaX8P05Ua0P","executionInfo":{"status":"ok","timestamp":1741816167749,"user_tz":-60,"elapsed":10,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"e4693f43-f42d-4c4f-b601-908695083368"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Chi-Squared Difference Test\n","\n","        Df    AIC    BIC  Chisq Chisq diff RMSEA Df diff Pr(>Chisq)\n","fitmete 14 897.74 942.88 16.949                                    \n","fitmetp 19 890.68 918.46 19.886     2.9369     0       5     0.7097\n","\n"]}]},{"cell_type":"markdown","source":["Note that we compare the **Essentially tau-parallel** measurement model with the **Essentially tau-equivalent** model (**not** the Essentially tau-parallel measurement model with the **Tau-equivalent** model). The latter isn't possible as we can only compare models that results from each other by adding (or loosening) restrictions. In the **Essentially tau-parallel** measurement model we restrict discrimination power and reliability. In the **Tau-equivalent** model we also restrict discrimination power but further restrict the item difficulty to be equivalent across items. This means neither of the models results from the other one by adding (or loosening) a restriction but rather by dropping one restriction and adding another one. Such models can't be compared. On the other hand, the  **Essentially tau-parallel** measurement model results from the **Essentially tau-equivalent** model by adding the restriction of equivalent reliability. Thus, these models can be compared.  \n","\n","The comparison however yields in an ambiguous result. While AIC and BIC favor the **Essentially tau-parallel** measurement model, the $\\chi^2$ value suggests a better fit for the **Essentially tau-equivalent** model. However, the $\\chi^2$ values do not differ significantly (p > .05).   \n","\n","## 6. Tau-parallel measurement model\n","\n","Out of the models we looked at today, the **Tau-parallel** measurement model is the most restrictive one. It assumes that\n","\n","* items **are equivalent in their difficulty**\n","* items **are equivalent in their discrimination power**\n","* items are **equivalently reliable**  \n","\n","Therefore, all parameters (`Intercepts` section, `Latent variables` section and `Variances` section) are restricted.\n","\n","### Fit the model"],"metadata":{"id":"BAncgLraUkkX"}},{"cell_type":"code","source":["# Specify the model\n","ro.r(\"mtp <<- 'eta =~ item_1 + 1*item_2 + 1*item_3 + 1*item_4 + 1*item_5 + 1*item_6\\n\"\n","      \"item_1 ~ a*1\\n\"\n","      \"item_2 ~ a*1\\n\"\n","      \"item_3 ~ a*1\\n\"\n","      \"item_4 ~ a*1\\n\"\n","      \"item_5 ~ a*1\\n\"\n","      \"item_6 ~ a*1\\n\"\n","      \"item_1 ~~ b*item_1\\n\"\n","      \"item_2 ~~ b*item_2\\n\"\n","      \"item_3 ~~ b*item_3\\n\"\n","      \"item_4 ~~ b*item_4\\n\"\n","      \"item_5 ~~ b*item_5\\n\"\n","      \"item_6 ~~ b*item_6'\")\n","# Fit the model\n","ro.r('fitmtp <- sem(mtp, data=dat2, meanstructure=TRUE, estimator=\"ML\")')\n","# Print the output of the model for interpretation\n","summary_fitmtp = ro.r(\"summary(fitmtp, fit.measures=TRUE, standardized=TRUE)\")\n","print(summary_fitmtp)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3pnwHq_-UlPj","executionInfo":{"status":"ok","timestamp":1741816092968,"user_tz":-60,"elapsed":155,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"3f4b7e8c-997d-40f9-a6a7-7bd130a2d41e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["lavaan 0.6-19 ended normally after 13 iterations\n","\n","  Estimator                                         ML\n","  Optimization method                           NLMINB\n","  Number of model parameters                        13\n","  Number of equality constraints                    10\n","\n","  Number of observations                           238\n","\n","Model Test User Model:\n","                                                      \n","  Test statistic                               104.462\n","  Degrees of freedom                                24\n","  P-value (Chi-square)                           0.000\n","\n","Model Test Baseline Model:\n","\n","  Test statistic                               435.847\n","  Degrees of freedom                                15\n","  P-value                                        0.000\n","\n","User Model versus Baseline Model:\n","\n","  Comparative Fit Index (CFI)                    0.809\n","  Tucker-Lewis Index (TLI)                       0.881\n","\n","Loglikelihood and Information Criteria:\n","\n","  Loglikelihood user model (H0)               -479.627\n","  Loglikelihood unrestricted model (H1)       -427.396\n","                                                      \n","  Akaike (AIC)                                 965.254\n","  Bayesian (BIC)                               975.670\n","  Sample-size adjusted Bayesian (SABIC)        966.161\n","\n","Root Mean Square Error of Approximation:\n","\n","  RMSEA                                          0.119\n","  90 Percent confidence interval - lower         0.096\n","  90 Percent confidence interval - upper         0.142\n","  P-value H_0: RMSEA <= 0.050                    0.000\n","  P-value H_0: RMSEA >= 0.080                    0.997\n","\n","Standardized Root Mean Square Residual:\n","\n","  SRMR                                           0.109\n","\n","Parameter Estimates:\n","\n","  Standard errors                             Standard\n","  Information                                 Expected\n","  Information saturated (h1) model          Structured\n","\n","Latent Variables:\n","                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n","  eta =~                                                                \n","    item_1            1.000                               0.252    0.650\n","    item_2            1.000                               0.252    0.650\n","    item_3            1.000                               0.252    0.650\n","    item_4            1.000                               0.252    0.650\n","    item_5            1.000                               0.252    0.650\n","    item_6            1.000                               0.252    0.650\n","\n","Intercepts:\n","                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n","   .item_1     (a)    1.379    0.018   76.247    0.000    1.379    3.561\n","   .item_2     (a)    1.379    0.018   76.247    0.000    1.379    3.561\n","   .item_3     (a)    1.379    0.018   76.247    0.000    1.379    3.561\n","   .item_4     (a)    1.379    0.018   76.247    0.000    1.379    3.561\n","   .item_5     (a)    1.379    0.018   76.247    0.000    1.379    3.561\n","   .item_6     (a)    1.379    0.018   76.247    0.000    1.379    3.561\n","\n","Variances:\n","                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n","   .item_1     (b)    0.087    0.004   24.393    0.000    0.087    0.577\n","   .item_2     (b)    0.087    0.004   24.393    0.000    0.087    0.577\n","   .item_3     (b)    0.087    0.004   24.393    0.000    0.087    0.577\n","   .item_4     (b)    0.087    0.004   24.393    0.000    0.087    0.577\n","   .item_5     (b)    0.087    0.004   24.393    0.000    0.087    0.577\n","   .item_6     (b)    0.087    0.004   24.393    0.000    0.087    0.577\n","    eta               0.063    0.007    8.858    0.000    1.000    1.000\n","\n","\n"]}]},{"cell_type":"markdown","source":["As you can see, loadings, intercepts and errors are restricted. The interpretation of the fit indices is analogous to the **Tau Congeneric** measurement model (see above). You might notice that the model fit (as indicated by the $\\chi^2$ value) declines with more restrictions being added to the models. While the (least restrictive) Tau Congeneric measurement model has a $\\chi^2$ value of 9.568, the (most restrictive) Tau-parallel measurement model has a $\\chi^2$ value of 104.462.\n","\n","### Compare model fit\n","\n","Since the **Tau-parallel** measurement model results from further restricting the **Essentially tau-parallel** measurement model OR from further restricting the **Tau-equivalent** model we can test the **Tau-parallel** measurement model against both models.\n"],"metadata":{"id":"CH_KAfCgVO-R"}},{"cell_type":"code","source":["# Perform anova and print indexes\n","anova_metp_mtp = ro.r(\"anova(fitmetp, fitmtp)\") #Tau-parallel measurement model vs. Essentially tau-parallel measurement model\n","print(anova_metp_mtp)\n","\n","anova_mte_mtp = ro.r(\"anova(fitmte, fitmtp)\") #Tau-parallel measurement model vs. Tau-equivalent measurement model\n","print(anova_mte_mtp)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FM2iVDMuVRQR","executionInfo":{"status":"ok","timestamp":1741816236747,"user_tz":-60,"elapsed":31,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"0d255f49-623a-45ba-ff4e-cf3bdc7ab925"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Chi-Squared Difference Test\n","\n","        Df    AIC    BIC   Chisq Chisq diff   RMSEA Df diff Pr(>Chisq)    \n","fitmetp 19 890.68 918.46  19.886                                          \n","fitmtp  24 965.25 975.67 104.462     84.576 0.25859       5  < 2.2e-16 ***\n","---\n","Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n","\n","\n","Chi-Squared Difference Test\n","\n","       Df    AIC    BIC  Chisq Chisq diff RMSEA Df diff Pr(>Chisq)\n","fitmte 19 970.91 998.69 100.12                                    \n","fitmtp 24 965.25 975.67 104.46     4.3457     0       5     0.5008\n","\n"]}]},{"cell_type":"markdown","source":["The first comparison suggests that the **Essentially tau-parallel** measurement model provides a significantly better fit to the data as compared to the Tau-parallel measurement model as indicated by $\\chi^2$, AIC and BIC.\n","Further, we see that there seems to be no significant different in model fit between the **Tau-parallel** measurement model and the **Tau-equivalent** model, although AIC and BIC slightly favor the Tau-parallel measurement model. This advantage in model fit is however not due to the model providing a better fit to the data but rather due to the **Tau-parallel** measurement model having less parameters to be estimated (i.e. it is a simpler model).\n","\n","## 7. And now?\n","\n","One might ask what we should conclude / infer from these models.  \n","Lets look again at the last comparisons."],"metadata":{"id":"7jSI0axcVRj0"}},{"cell_type":"code","source":["anova_metp_mtp = ro.r(\"anova(fitmetp, fitmtp)\") #Tau-parallel measurement model vs. Essentially tau-parallel measurement model\n","print(anova_metp_mtp)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a_pwdE8VV0vW","executionInfo":{"status":"ok","timestamp":1741816334088,"user_tz":-60,"elapsed":7,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"ee7494de-da48-4e32-bece-cdd13f161422"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Chi-Squared Difference Test\n","\n","        Df    AIC    BIC   Chisq Chisq diff   RMSEA Df diff Pr(>Chisq)    \n","fitmetp 19 890.68 918.46  19.886                                          \n","fitmtp  24 965.25 975.67 104.462     84.576 0.25859       5  < 2.2e-16 ***\n","---\n","Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n","\n"]}]},{"cell_type":"markdown","source":["You should remember that the **Tau-parallel** measurement model restricts **discrimination power** (loadings), **difficulty** (intercepts) and **reliability** (errors). The **Essentially tau-parallel measurement model** only restricts **discrimination power** and **reliability**. We see in the model comparison that the Essentially tau-parallel measurement model provides a significantly better fit to the data. From this we can infer that freely estimating the intercepts provides a significantly better fit as compared to assuming them to be equivalent. In other words, the data suggests that our items are **not equally difficult**."],"metadata":{"id":"O4Xio0q9V2Uy"}},{"cell_type":"code","source":["anova_mte_mtp = ro.r(\"anova(fitmte, fitmtp)\") #Tau-parallel measurement model vs. Tau-equivalent measurement model\n","print(anova_mte_mtp)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sLGv9wJPV2lD","executionInfo":{"status":"ok","timestamp":1741816353617,"user_tz":-60,"elapsed":39,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"65ecf9b1-e746-4fb0-eaf2-d68c1e191fa0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Chi-Squared Difference Test\n","\n","       Df    AIC    BIC  Chisq Chisq diff RMSEA Df diff Pr(>Chisq)\n","fitmte 19 970.91 998.69 100.12                                    \n","fitmtp 24 965.25 975.67 104.46     4.3457     0       5     0.5008\n","\n"]}]},{"cell_type":"markdown","source":["Lets look at the other comparison. Again, you should remember that the **Tau-parallel measurement model** restricts **discrimination power** (loadings), **difficulty** (intercepts) and **reliability** (errors). The **Tau-equivalent measurement model** only restricts **discrimination power** and **difficulty**. The model comparison shows that the more flexible model (Tau-equivalent measurement model) does **not** provide a significantly better fit to the data, meaning there is no significant differences in model fit when we freely estimate the reliability as compared to assuming equal reliability across all items.   \n","Think of it like that: When the more flexible model gives equal reliability scores (errors) for all items, restricting them in a less flexible model does not change a lot, hence there are no significant differences in model fit. In other words, from this comparison we can conclude that our items are **equally reliable**.  \n","\n","According to this approach, would you say our items are equal in discrimination power?\n","\n","## 8. Extract factor scores\n","\n","Lastly, we can also extract person coefficients (i.e. factor scores) using the `predict` function."],"metadata":{"id":"zXrK1fd7WG7X"}},{"cell_type":"code","source":["ppar = ro.r(\"predict(fitmtc)\")\n","print(ppar)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5cr-1ZApWHW_","executionInfo":{"status":"ok","timestamp":1741816394062,"user_tz":-60,"elapsed":17,"user":{"displayName":"Tim Dreßler","userId":"10678244503421566183"}},"outputId":"7f838ff2-ae76-4fcf-fcec-f2e8efb9d4e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 0.12073671]\n"," [ 0.2399859 ]\n"," [-0.00106554]\n"," [-0.0080816 ]\n"," [-0.20787835]\n"," [-0.18320165]\n"," [ 0.39365629]\n"," [ 0.27002988]\n"," [-0.0353721 ]\n"," [-0.11238712]\n"," [-0.03732313]\n"," [ 0.27998964]\n"," [-0.08850881]\n"," [ 0.09130247]\n"," [-0.10579118]\n"," [ 0.11052924]\n"," [ 0.10778979]\n"," [-0.32484031]\n"," [ 0.20636155]\n"," [ 0.17023445]\n"," [ 0.26021663]\n"," [ 0.27197654]\n"," [-0.17114061]\n"," [-0.1423634 ]\n"," [ 0.36606071]\n"," [-0.07478522]\n"," [-0.08269706]\n"," [ 0.06433197]\n"," [ 0.15894493]\n"," [ 0.04430302]\n"," [-0.50563021]\n"," [ 0.02755227]\n"," [ 0.0045081 ]\n"," [ 0.05691382]\n"," [ 0.06471399]\n"," [ 0.11226692]\n"," [ 0.01009598]\n"," [ 0.03662523]\n"," [ 0.0371341 ]\n"," [-0.07487552]\n"," [ 0.06196375]\n"," [-0.08277975]\n"," [ 0.11805626]\n"," [ 0.16415042]\n"," [-0.14367311]\n"," [ 0.02914086]\n"," [ 0.12025572]\n"," [ 0.11489691]\n"," [-0.21777332]\n"," [ 0.15941502]\n"," [ 0.22347693]\n"," [ 0.06400319]\n"," [ 0.01480666]\n"," [-0.06774294]\n"," [ 0.37054273]\n"," [ 0.06061693]\n"," [ 0.2043271 ]\n"," [-0.21180907]\n"," [ 0.02470239]\n"," [ 0.22176066]\n"," [-0.20330248]\n"," [ 0.04473016]\n"," [ 0.0934721 ]\n"," [-0.23556783]\n"," [ 0.01584813]\n"," [ 0.2483084 ]\n"," [-0.38746985]\n"," [-0.07089748]\n"," [ 0.21088851]\n"," [ 0.07334115]\n"," [ 0.17564439]\n"," [-0.05144462]\n"," [-0.07089966]\n"," [ 0.24499844]\n"," [ 0.10151722]\n"," [-0.06901617]\n"," [ 0.0456448 ]\n"," [ 0.16319454]\n"," [ 0.17989838]\n"," [-0.13421496]\n"," [-0.24170618]\n"," [-0.46505992]\n"," [ 0.03180718]\n"," [ 0.0664597 ]\n"," [ 0.03337448]\n"," [-0.06008466]\n"," [-0.28387795]\n"," [ 0.08465731]\n"," [ 0.13409875]\n"," [ 0.05692584]\n"," [-0.20550244]\n"," [ 0.08144463]\n"," [-0.04605298]\n"," [ 0.21947592]\n"," [-0.05537016]\n"," [ 0.24685093]\n"," [-0.17619315]\n"," [ 0.05007634]\n"," [ 0.13997748]\n"," [ 0.07674666]\n"," [-0.18686077]\n"," [ 0.1622401 ]\n"," [ 0.38272082]\n"," [-0.14227858]\n"," [-0.23937826]\n"," [ 0.10285074]\n"," [-0.1722375 ]\n"," [ 0.08698164]\n"," [-0.03229419]\n"," [ 0.23368831]\n"," [ 0.02511868]\n"," [ 0.20433532]\n"," [ 0.16165382]\n"," [-0.24442257]\n"," [ 0.18407926]\n"," [-0.12782877]\n"," [-0.48683382]\n"," [-0.0370809 ]\n"," [ 0.14700427]\n"," [ 0.1175338 ]\n"," [-0.02603344]\n"," [ 0.01843564]\n"," [ 0.14197215]\n"," [-0.16042558]\n"," [-0.12501578]\n"," [ 0.39887482]\n"," [-0.05839251]\n"," [-0.27333906]\n"," [ 0.09378877]\n"," [-0.2859779 ]\n"," [-0.06329123]\n"," [ 0.28809748]\n"," [ 0.02208326]\n"," [ 0.02926573]\n"," [-0.07572882]\n"," [ 0.05136836]\n"," [-0.13451622]\n"," [-0.28482411]\n"," [-0.05971757]\n"," [-0.00696119]\n"," [-0.2056506 ]\n"," [ 0.03240509]\n"," [ 0.31028298]\n"," [ 0.00434217]\n"," [-0.08589899]\n"," [-0.11646003]\n"," [-0.15879802]\n"," [ 0.02091822]\n"," [-0.0185422 ]\n"," [ 0.19232778]\n"," [ 0.21641285]\n"," [-0.17676105]\n"," [-0.13089798]\n"," [ 0.08564287]\n"," [ 0.29361047]\n"," [-0.30384829]\n"," [-0.15604862]\n"," [ 0.22365418]\n"," [-0.01888986]\n"," [ 0.2558285 ]\n"," [-0.0931723 ]\n"," [-0.14190415]\n"," [-0.19480303]\n"," [-0.23080607]\n"," [ 0.01103917]\n"," [-0.05970047]\n"," [-0.13721802]\n"," [-0.22745276]\n"," [-0.08843777]\n"," [-0.25607412]\n"," [-0.29596978]\n"," [-0.21146914]\n"," [ 0.18616632]\n"," [ 0.07984204]\n"," [ 0.10033143]\n"," [ 0.16198517]\n"," [-0.19764113]\n"," [-0.1945785 ]\n"," [ 0.01118844]\n"," [-0.16381194]\n"," [-0.11198058]\n"," [-0.2099628 ]\n"," [-0.02347381]\n"," [ 0.24895667]\n"," [-0.03948673]\n"," [-0.1448985 ]\n"," [ 0.31304109]\n"," [-0.09518704]\n"," [-0.16975589]\n"," [-0.12045449]\n"," [ 0.1817603 ]\n"," [ 0.02893207]\n"," [-0.15751139]\n"," [ 0.11845567]\n"," [-0.09532234]\n"," [-0.78347861]\n"," [ 0.10470245]\n"," [ 0.12724124]\n"," [ 0.50450487]\n"," [ 0.16642292]\n"," [-0.00875061]\n"," [ 0.32828081]\n"," [ 0.22736694]\n"," [-0.20620184]\n"," [ 0.36810431]\n"," [ 0.25601399]\n"," [ 0.04549933]\n"," [ 0.13245698]\n"," [-0.06223831]\n"," [ 0.02825288]\n"," [ 0.2033174 ]\n"," [-0.17282055]\n"," [ 0.11156832]\n"," [ 0.26545191]\n"," [-0.29160059]\n"," [ 0.04155404]\n"," [ 0.24093035]\n"," [ 0.04186059]\n"," [-0.29186336]\n"," [-0.93529234]\n"," [-0.58976593]\n"," [ 0.18656583]\n"," [ 0.24061333]\n"," [-0.03180274]\n"," [-0.00312996]\n"," [-0.07429995]\n"," [-0.01376578]\n"," [ 0.30334668]\n"," [ 0.05238216]\n"," [-0.02575791]\n"," [-0.36423244]\n"," [ 0.03893627]\n"," [-0.11997552]\n"," [ 0.30172281]\n"," [ 0.12893153]\n"," [ 0.25059732]\n"," [-0.15500374]\n"," [-0.88093103]]\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"1shSM8oE3V3nElvkpfKPtfJNamsVKnTSR","timestamp":1741293629262},{"file_id":"1oY59GO8mlzEJZlf-csY2pKRUXDCCIMFo","timestamp":1741164113567},{"file_id":"1_Hdy9GX2W03RQoKnijnEid9-KJzzTmJi","timestamp":1740862927421}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}