{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1831debe",
   "metadata": {},
   "source": [
    "# 6.3 Tau-Parallel Models\n",
    "##  Essentially tau-parallel measurement model\n",
    "\n",
    "The **Essentially tau-parallel** measurement model looses one restriction compared to the Tau-equivalent model by letting the intercepts vary. However, it restricts the items to have equivalent reliability. It assumes that\n",
    "\n",
    "* items **differ in their difficulty**\n",
    "* items are equivalent in their discrimination power\n",
    "* items are **equivalently reliable**  \n",
    "\n",
    "We therefore only get estimates for the difficulty of the items (`Intercepts` section). Discrimination power (`Latent variables` section) and Reliability (`Variances` section) are fixed across items.\n",
    "\n",
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d003d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lavaan 0.6-19 ended normally after 13 iterations\n",
      "\n",
      "  Estimator                                         ML\n",
      "  Optimization method                           NLMINB\n",
      "  Number of model parameters                        13\n",
      "  Number of equality constraints                     5\n",
      "\n",
      "  Number of observations                           238\n",
      "\n",
      "Model Test User Model:\n",
      "                                                      \n",
      "  Test statistic                                19.886\n",
      "  Degrees of freedom                                19\n",
      "  P-value (Chi-square)                           0.401\n",
      "\n",
      "Model Test Baseline Model:\n",
      "\n",
      "  Test statistic                               435.847\n",
      "  Degrees of freedom                                15\n",
      "  P-value                                        0.000\n",
      "\n",
      "User Model versus Baseline Model:\n",
      "\n",
      "  Comparative Fit Index (CFI)                    0.998\n",
      "  Tucker-Lewis Index (TLI)                       0.998\n",
      "\n",
      "Loglikelihood and Information Criteria:\n",
      "\n",
      "  Loglikelihood user model (H0)               -437.339\n",
      "  Loglikelihood unrestricted model (H1)       -427.396\n",
      "                                                      \n",
      "  Akaike (AIC)                                 890.677\n",
      "  Bayesian (BIC)                               918.455\n",
      "  Sample-size adjusted Bayesian (SABIC)        893.098\n",
      "\n",
      "Root Mean Square Error of Approximation:\n",
      "\n",
      "  RMSEA                                          0.014\n",
      "  90 Percent confidence interval - lower         0.000\n",
      "  90 Percent confidence interval - upper         0.059\n",
      "  P-value H_0: RMSEA <= 0.050                    0.884\n",
      "  P-value H_0: RMSEA >= 0.080                    0.003\n",
      "\n",
      "Standardized Root Mean Square Residual:\n",
      "\n",
      "  SRMR                                           0.059\n",
      "\n",
      "Parameter Estimates:\n",
      "\n",
      "  Standard errors                             Standard\n",
      "  Information                                 Expected\n",
      "  Information saturated (h1) model          Structured\n",
      "\n",
      "Latent Variables:\n",
      "                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n",
      "  eta =~                                                                \n",
      "    item_1            1.000                               0.254    0.667\n",
      "    item_2            1.000                               0.254    0.667\n",
      "    item_3            1.000                               0.254    0.667\n",
      "    item_4            1.000                               0.254    0.667\n",
      "    item_5            1.000                               0.254    0.667\n",
      "    item_6            1.000                               0.254    0.667\n",
      "\n",
      "Intercepts:\n",
      "                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n",
      "   .item_1            1.504    0.025   60.923    0.000    1.504    3.949\n",
      "   .item_2            1.423    0.025   57.637    0.000    1.423    3.736\n",
      "   .item_3            1.392    0.025   56.392    0.000    1.392    3.655\n",
      "   .item_4            1.305    0.025   52.849    0.000    1.305    3.426\n",
      "   .item_5            1.346    0.025   54.537    0.000    1.346    3.535\n",
      "   .item_6            1.306    0.025   52.890    0.000    1.306    3.428\n",
      "\n",
      "Variances:\n",
      "                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n",
      "   .item_1     (b)    0.081    0.003   24.393    0.000    0.081    0.556\n",
      "   .item_2     (b)    0.081    0.003   24.393    0.000    0.081    0.556\n",
      "   .item_3     (b)    0.081    0.003   24.393    0.000    0.081    0.556\n",
      "   .item_4     (b)    0.081    0.003   24.393    0.000    0.081    0.556\n",
      "   .item_5     (b)    0.081    0.003   24.393    0.000    0.081    0.556\n",
      "   .item_6     (b)    0.081    0.003   24.393    0.000    0.081    0.556\n",
      "    eta               0.064    0.007    9.001    0.000    1.000    1.000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Specify the model\n",
    "ro.r(\"metp <<- 'eta =~ item_1 + 1*item_2 + 1*item_3 + 1*item_4 + 1*item_5 + 1*item_6\\n\"\n",
    "      \"item_1 ~~ b*item_1\\n\"\n",
    "      \"item_2 ~~ b*item_2\\n\"\n",
    "      \"item_3 ~~ b*item_3\\n\"\n",
    "      \"item_4 ~~ b*item_4\\n\"\n",
    "      \"item_5 ~~ b*item_5\\n\"\n",
    "      \"item_6 ~~ b*item_6'\")\n",
    "\n",
    "# Fit the model\n",
    "ro.r('fitmetp <- sem(metp, data=dat2, meanstructure=TRUE, estimator=\"ML\")')\n",
    "# Print the output of the model for interpretation\n",
    "summary_fitmetp = ro.r(\"summary(fitmetp, fit.measures=TRUE, standardized=TRUE)\")\n",
    "print(summary_fitmetp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e313124",
   "metadata": {},
   "source": [
    "In the output we see fixed parameters in the `Latent variables` section and in the `Variances` section. However, intercepts (i.e. item difficulties) are allowed to vary) as you can see in the `Intercepts` section. `item_1` has the highest difficulty (1.504) and `item_4`has the lowest difficulty (1.305). This means that an individual with a score of 0 for the latent variable (here: **emotional clarity**) (or a mean score if the latent variable is centered) scores the lowest on `item_4` and highest on `item_1`. The interpretation of the fit indices is analogous to the **Tau Congeneric** measurement model (see above).\n",
    "\n",
    "### Compare model fit\n",
    "\n",
    "As before, we can use the `anova()` function to compare the model fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc39517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chi-Squared Difference Test\n",
      "\n",
      "        Df    AIC    BIC  Chisq Chisq diff RMSEA Df diff Pr(>Chisq)\n",
      "fitmete 14 897.74 942.88 16.949                                    \n",
      "fitmetp 19 890.68 918.46 19.886     2.9369     0       5     0.7097\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform anova and print indexes\n",
    "anova_mete_mept = ro.r(\"anova(fitmete, fitmetp)\")\n",
    "print(anova_mete_mept)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7890f2e0",
   "metadata": {},
   "source": [
    "Note that we compare the **Essentially tau-parallel** measurement model with the **Essentially tau-equivalent** model (**not** the Essentially tau-parallel measurement model with the **Tau-equivalent** model). The latter isn't possible as we can only compare models that results from each other by adding (or loosening) restrictions. In the **Essentially tau-parallel** measurement model we restrict discrimination power and reliability. In the **Tau-equivalent** model we also restrict discrimination power but further restrict the item difficulty to be equivalent across items. This means neither of the models results from the other one by adding (or loosening) a restriction but rather by dropping one restriction and adding another one. Such models can't be compared. On the other hand, the  **Essentially tau-parallel** measurement model results from the **Essentially tau-equivalent** model by adding the restriction of equivalent reliability. Thus, these models can be compared.  \n",
    "\n",
    "The comparison however yields in an ambiguous result. While AIC and BIC favor the **Essentially tau-parallel** measurement model, the $\\chi^2$ value suggests a better fit for the **Essentially tau-equivalent** model. However, the $\\chi^2$ values do not differ significantly (p > .05).   \n",
    "\n",
    "## Tau-parallel measurement model\n",
    "\n",
    "Out of the models we looked at today, the **Tau-parallel** measurement model is the most restrictive one. It assumes that\n",
    "\n",
    "* items **are equivalent in their difficulty**\n",
    "* items **are equivalent in their discrimination power**\n",
    "* items are **equivalently reliable**  \n",
    "\n",
    "Therefore, all parameters (`Intercepts` section, `Latent variables` section and `Variances` section) are restricted.\n",
    "\n",
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc33c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lavaan 0.6-19 ended normally after 13 iterations\n",
      "\n",
      "  Estimator                                         ML\n",
      "  Optimization method                           NLMINB\n",
      "  Number of model parameters                        13\n",
      "  Number of equality constraints                    10\n",
      "\n",
      "  Number of observations                           238\n",
      "\n",
      "Model Test User Model:\n",
      "                                                      \n",
      "  Test statistic                               104.462\n",
      "  Degrees of freedom                                24\n",
      "  P-value (Chi-square)                           0.000\n",
      "\n",
      "Model Test Baseline Model:\n",
      "\n",
      "  Test statistic                               435.847\n",
      "  Degrees of freedom                                15\n",
      "  P-value                                        0.000\n",
      "\n",
      "User Model versus Baseline Model:\n",
      "\n",
      "  Comparative Fit Index (CFI)                    0.809\n",
      "  Tucker-Lewis Index (TLI)                       0.881\n",
      "\n",
      "Loglikelihood and Information Criteria:\n",
      "\n",
      "  Loglikelihood user model (H0)               -479.627\n",
      "  Loglikelihood unrestricted model (H1)       -427.396\n",
      "                                                      \n",
      "  Akaike (AIC)                                 965.254\n",
      "  Bayesian (BIC)                               975.670\n",
      "  Sample-size adjusted Bayesian (SABIC)        966.161\n",
      "\n",
      "Root Mean Square Error of Approximation:\n",
      "\n",
      "  RMSEA                                          0.119\n",
      "  90 Percent confidence interval - lower         0.096\n",
      "  90 Percent confidence interval - upper         0.142\n",
      "  P-value H_0: RMSEA <= 0.050                    0.000\n",
      "  P-value H_0: RMSEA >= 0.080                    0.997\n",
      "\n",
      "Standardized Root Mean Square Residual:\n",
      "\n",
      "  SRMR                                           0.109\n",
      "\n",
      "Parameter Estimates:\n",
      "\n",
      "  Standard errors                             Standard\n",
      "  Information                                 Expected\n",
      "  Information saturated (h1) model          Structured\n",
      "\n",
      "Latent Variables:\n",
      "                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n",
      "  eta =~                                                                \n",
      "    item_1            1.000                               0.252    0.650\n",
      "    item_2            1.000                               0.252    0.650\n",
      "    item_3            1.000                               0.252    0.650\n",
      "    item_4            1.000                               0.252    0.650\n",
      "    item_5            1.000                               0.252    0.650\n",
      "    item_6            1.000                               0.252    0.650\n",
      "\n",
      "Intercepts:\n",
      "                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n",
      "   .item_1     (a)    1.379    0.018   76.247    0.000    1.379    3.561\n",
      "   .item_2     (a)    1.379    0.018   76.247    0.000    1.379    3.561\n",
      "   .item_3     (a)    1.379    0.018   76.247    0.000    1.379    3.561\n",
      "   .item_4     (a)    1.379    0.018   76.247    0.000    1.379    3.561\n",
      "   .item_5     (a)    1.379    0.018   76.247    0.000    1.379    3.561\n",
      "   .item_6     (a)    1.379    0.018   76.247    0.000    1.379    3.561\n",
      "\n",
      "Variances:\n",
      "                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n",
      "   .item_1     (b)    0.087    0.004   24.393    0.000    0.087    0.577\n",
      "   .item_2     (b)    0.087    0.004   24.393    0.000    0.087    0.577\n",
      "   .item_3     (b)    0.087    0.004   24.393    0.000    0.087    0.577\n",
      "   .item_4     (b)    0.087    0.004   24.393    0.000    0.087    0.577\n",
      "   .item_5     (b)    0.087    0.004   24.393    0.000    0.087    0.577\n",
      "   .item_6     (b)    0.087    0.004   24.393    0.000    0.087    0.577\n",
      "    eta               0.063    0.007    8.858    0.000    1.000    1.000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Specify the model\n",
    "ro.r(\"mtp <<- 'eta =~ item_1 + 1*item_2 + 1*item_3 + 1*item_4 + 1*item_5 + 1*item_6\\n\"\n",
    "      \"item_1 ~ a*1\\n\"\n",
    "      \"item_2 ~ a*1\\n\"\n",
    "      \"item_3 ~ a*1\\n\"\n",
    "      \"item_4 ~ a*1\\n\"\n",
    "      \"item_5 ~ a*1\\n\"\n",
    "      \"item_6 ~ a*1\\n\"\n",
    "      \"item_1 ~~ b*item_1\\n\"\n",
    "      \"item_2 ~~ b*item_2\\n\"\n",
    "      \"item_3 ~~ b*item_3\\n\"\n",
    "      \"item_4 ~~ b*item_4\\n\"\n",
    "      \"item_5 ~~ b*item_5\\n\"\n",
    "      \"item_6 ~~ b*item_6'\")\n",
    "# Fit the model\n",
    "ro.r('fitmtp <- sem(mtp, data=dat2, meanstructure=TRUE, estimator=\"ML\")')\n",
    "# Print the output of the model for interpretation\n",
    "summary_fitmtp = ro.r(\"summary(fitmtp, fit.measures=TRUE, standardized=TRUE)\")\n",
    "print(summary_fitmtp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93640897",
   "metadata": {},
   "source": [
    "As you can see, loadings, intercepts and errors are restricted. The interpretation of the fit indices is analogous to the **Tau Congeneric** measurement model (see above). You might notice that the model fit (as indicated by the $\\chi^2$ value) declines with more restrictions being added to the models. While the (least restrictive) Tau Congeneric measurement model has a $\\chi^2$ value of 9.568, the (most restrictive) Tau-parallel measurement model has a $\\chi^2$ value of 104.462.\n",
    "\n",
    "### Compare model fit\n",
    "\n",
    "Since the **Tau-parallel** measurement model results from further restricting the **Essentially tau-parallel** measurement model OR from further restricting the **Tau-equivalent** model we can test the **Tau-parallel** measurement model against both models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2f1ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chi-Squared Difference Test\n",
      "\n",
      "        Df    AIC    BIC   Chisq Chisq diff   RMSEA Df diff Pr(>Chisq)    \n",
      "fitmetp 19 890.68 918.46  19.886                                          \n",
      "fitmtp  24 965.25 975.67 104.462     84.576 0.25859       5  < 2.2e-16 ***\n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "\n",
      "Chi-Squared Difference Test\n",
      "\n",
      "       Df    AIC    BIC  Chisq Chisq diff RMSEA Df diff Pr(>Chisq)\n",
      "fitmte 19 970.91 998.69 100.12                                    \n",
      "fitmtp 24 965.25 975.67 104.46     4.3457     0       5     0.5008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform anova and print indexes\n",
    "anova_metp_mtp = ro.r(\"anova(fitmetp, fitmtp)\") #Tau-parallel measurement model vs. Essentially tau-parallel measurement model\n",
    "print(anova_metp_mtp)\n",
    "\n",
    "anova_mte_mtp = ro.r(\"anova(fitmte, fitmtp)\") #Tau-parallel measurement model vs. Tau-equivalent measurement model\n",
    "print(anova_mte_mtp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48d6932",
   "metadata": {},
   "source": [
    "The first comparison suggests that the **Essentially tau-parallel** measurement model provides a significantly better fit to the data as compared to the Tau-parallel measurement model as indicated by $\\chi^2$, AIC and BIC.\n",
    "Further, we see that there seems to be no significant different in model fit between the **Tau-parallel** measurement model and the **Tau-equivalent** model, although AIC and BIC slightly favor the Tau-parallel measurement model. This advantage in model fit is however not due to the model providing a better fit to the data but rather due to the **Tau-parallel** measurement model having less parameters to be estimated (i.e. it is a simpler model).\n",
    "\n",
    "## And now?\n",
    "\n",
    "One might ask what we should conclude / infer from these models.  \n",
    "Lets look again at the last comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39f599c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chi-Squared Difference Test\n",
      "\n",
      "        Df    AIC    BIC   Chisq Chisq diff   RMSEA Df diff Pr(>Chisq)    \n",
      "fitmetp 19 890.68 918.46  19.886                                          \n",
      "fitmtp  24 965.25 975.67 104.462     84.576 0.25859       5  < 2.2e-16 ***\n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "anova_metp_mtp = ro.r(\"anova(fitmetp, fitmtp)\") #Tau-parallel measurement model vs. Essentially tau-parallel measurement model\n",
    "print(anova_metp_mtp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6835d4",
   "metadata": {},
   "source": [
    "You should remember that the **Tau-parallel** measurement model restricts **discrimination power** (loadings), **difficulty** (intercepts) and **reliability** (errors). The **Essentially tau-parallel measurement model** only restricts **discrimination power** and **reliability**. We see in the model comparison that the Essentially tau-parallel measurement model provides a significantly better fit to the data. From this we can infer that freely estimating the intercepts provides a significantly better fit as compared to assuming them to be equivalent. In other words, the data suggests that our items are **not equally difficult**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c79b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chi-Squared Difference Test\n",
      "\n",
      "       Df    AIC    BIC  Chisq Chisq diff RMSEA Df diff Pr(>Chisq)\n",
      "fitmte 19 970.91 998.69 100.12                                    \n",
      "fitmtp 24 965.25 975.67 104.46     4.3457     0       5     0.5008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "anova_mte_mtp = ro.r(\"anova(fitmte, fitmtp)\") #Tau-parallel measurement model vs. Tau-equivalent measurement model\n",
    "print(anova_mte_mtp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c32076",
   "metadata": {},
   "source": [
    "Lets look at the other comparison. Again, you should remember that the **Tau-parallel measurement model** restricts **discrimination power** (loadings), **difficulty** (intercepts) and **reliability** (errors). The **Tau-equivalent measurement model** only restricts **discrimination power** and **difficulty**. The model comparison shows that the more flexible model (Tau-equivalent measurement model) does **not** provide a significantly better fit to the data, meaning there is no significant differences in model fit when we freely estimate the reliability as compared to assuming equal reliability across all items.   \n",
    "Think of it like that: When the more flexible model gives equal reliability scores (errors) for all items, restricting them in a less flexible model does not change a lot, hence there are no significant differences in model fit. In other words, from this comparison we can conclude that our items are **equally reliable**.  \n",
    "\n",
    "According to this approach, would you say our items are equal in discrimination power?\n",
    "\n",
    "## Extract factor scores\n",
    "\n",
    "Lastly, we can also extract person coefficients (i.e. factor scores) using the `predict` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a5773a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.12073671]\n",
      " [ 0.2399859 ]\n",
      " [-0.00106554]\n",
      " [-0.0080816 ]\n",
      " [-0.20787835]\n",
      " [-0.18320165]\n",
      " [ 0.39365629]\n",
      " [ 0.27002988]\n",
      " [-0.0353721 ]\n",
      " [-0.11238712]\n",
      " [-0.03732313]\n",
      " [ 0.27998964]\n",
      " [-0.08850881]\n",
      " [ 0.09130247]\n",
      " [-0.10579118]\n",
      " [ 0.11052924]\n",
      " [ 0.10778979]\n",
      " [-0.32484031]\n",
      " [ 0.20636155]\n",
      " [ 0.17023445]\n",
      " [ 0.26021663]\n",
      " [ 0.27197654]\n",
      " [-0.17114061]\n",
      " [-0.1423634 ]\n",
      " [ 0.36606071]\n",
      " [-0.07478522]\n",
      " [-0.08269706]\n",
      " [ 0.06433197]\n",
      " [ 0.15894493]\n",
      " [ 0.04430302]\n",
      " [-0.50563021]\n",
      " [ 0.02755227]\n",
      " [ 0.0045081 ]\n",
      " [ 0.05691382]\n",
      " [ 0.06471399]\n",
      " [ 0.11226692]\n",
      " [ 0.01009598]\n",
      " [ 0.03662523]\n",
      " [ 0.0371341 ]\n",
      " [-0.07487552]\n",
      " [ 0.06196375]\n",
      " [-0.08277975]\n",
      " [ 0.11805626]\n",
      " [ 0.16415042]\n",
      " [-0.14367311]\n",
      " [ 0.02914086]\n",
      " [ 0.12025572]\n",
      " [ 0.11489691]\n",
      " [-0.21777332]\n",
      " [ 0.15941502]\n",
      " [ 0.22347693]\n",
      " [ 0.06400319]\n",
      " [ 0.01480666]\n",
      " [-0.06774294]\n",
      " [ 0.37054273]\n",
      " [ 0.06061693]\n",
      " [ 0.2043271 ]\n",
      " [-0.21180907]\n",
      " [ 0.02470239]\n",
      " [ 0.22176066]\n",
      " [-0.20330248]\n",
      " [ 0.04473016]\n",
      " [ 0.0934721 ]\n",
      " [-0.23556783]\n",
      " [ 0.01584813]\n",
      " [ 0.2483084 ]\n",
      " [-0.38746985]\n",
      " [-0.07089748]\n",
      " [ 0.21088851]\n",
      " [ 0.07334115]\n",
      " [ 0.17564439]\n",
      " [-0.05144462]\n",
      " [-0.07089966]\n",
      " [ 0.24499844]\n",
      " [ 0.10151722]\n",
      " [-0.06901617]\n",
      " [ 0.0456448 ]\n",
      " [ 0.16319454]\n",
      " [ 0.17989838]\n",
      " [-0.13421496]\n",
      " [-0.24170618]\n",
      " [-0.46505992]\n",
      " [ 0.03180718]\n",
      " [ 0.0664597 ]\n",
      " [ 0.03337448]\n",
      " [-0.06008466]\n",
      " [-0.28387795]\n",
      " [ 0.08465731]\n",
      " [ 0.13409875]\n",
      " [ 0.05692584]\n",
      " [-0.20550244]\n",
      " [ 0.08144463]\n",
      " [-0.04605298]\n",
      " [ 0.21947592]\n",
      " [-0.05537016]\n",
      " [ 0.24685093]\n",
      " [-0.17619315]\n",
      " [ 0.05007634]\n",
      " [ 0.13997748]\n",
      " [ 0.07674666]\n",
      " [-0.18686077]\n",
      " [ 0.1622401 ]\n",
      " [ 0.38272082]\n",
      " [-0.14227858]\n",
      " [-0.23937826]\n",
      " [ 0.10285074]\n",
      " [-0.1722375 ]\n",
      " [ 0.08698164]\n",
      " [-0.03229419]\n",
      " [ 0.23368831]\n",
      " [ 0.02511868]\n",
      " [ 0.20433532]\n",
      " [ 0.16165382]\n",
      " [-0.24442257]\n",
      " [ 0.18407926]\n",
      " [-0.12782877]\n",
      " [-0.48683382]\n",
      " [-0.0370809 ]\n",
      " [ 0.14700427]\n",
      " [ 0.1175338 ]\n",
      " [-0.02603344]\n",
      " [ 0.01843564]\n",
      " [ 0.14197215]\n",
      " [-0.16042558]\n",
      " [-0.12501578]\n",
      " [ 0.39887482]\n",
      " [-0.05839251]\n",
      " [-0.27333906]\n",
      " [ 0.09378877]\n",
      " [-0.2859779 ]\n",
      " [-0.06329123]\n",
      " [ 0.28809748]\n",
      " [ 0.02208326]\n",
      " [ 0.02926573]\n",
      " [-0.07572882]\n",
      " [ 0.05136836]\n",
      " [-0.13451622]\n",
      " [-0.28482411]\n",
      " [-0.05971757]\n",
      " [-0.00696119]\n",
      " [-0.2056506 ]\n",
      " [ 0.03240509]\n",
      " [ 0.31028298]\n",
      " [ 0.00434217]\n",
      " [-0.08589899]\n",
      " [-0.11646003]\n",
      " [-0.15879802]\n",
      " [ 0.02091822]\n",
      " [-0.0185422 ]\n",
      " [ 0.19232778]\n",
      " [ 0.21641285]\n",
      " [-0.17676105]\n",
      " [-0.13089798]\n",
      " [ 0.08564287]\n",
      " [ 0.29361047]\n",
      " [-0.30384829]\n",
      " [-0.15604862]\n",
      " [ 0.22365418]\n",
      " [-0.01888986]\n",
      " [ 0.2558285 ]\n",
      " [-0.0931723 ]\n",
      " [-0.14190415]\n",
      " [-0.19480303]\n",
      " [-0.23080607]\n",
      " [ 0.01103917]\n",
      " [-0.05970047]\n",
      " [-0.13721802]\n",
      " [-0.22745276]\n",
      " [-0.08843777]\n",
      " [-0.25607412]\n",
      " [-0.29596978]\n",
      " [-0.21146914]\n",
      " [ 0.18616632]\n",
      " [ 0.07984204]\n",
      " [ 0.10033143]\n",
      " [ 0.16198517]\n",
      " [-0.19764113]\n",
      " [-0.1945785 ]\n",
      " [ 0.01118844]\n",
      " [-0.16381194]\n",
      " [-0.11198058]\n",
      " [-0.2099628 ]\n",
      " [-0.02347381]\n",
      " [ 0.24895667]\n",
      " [-0.03948673]\n",
      " [-0.1448985 ]\n",
      " [ 0.31304109]\n",
      " [-0.09518704]\n",
      " [-0.16975589]\n",
      " [-0.12045449]\n",
      " [ 0.1817603 ]\n",
      " [ 0.02893207]\n",
      " [-0.15751139]\n",
      " [ 0.11845567]\n",
      " [-0.09532234]\n",
      " [-0.78347861]\n",
      " [ 0.10470245]\n",
      " [ 0.12724124]\n",
      " [ 0.50450487]\n",
      " [ 0.16642292]\n",
      " [-0.00875061]\n",
      " [ 0.32828081]\n",
      " [ 0.22736694]\n",
      " [-0.20620184]\n",
      " [ 0.36810431]\n",
      " [ 0.25601399]\n",
      " [ 0.04549933]\n",
      " [ 0.13245698]\n",
      " [-0.06223831]\n",
      " [ 0.02825288]\n",
      " [ 0.2033174 ]\n",
      " [-0.17282055]\n",
      " [ 0.11156832]\n",
      " [ 0.26545191]\n",
      " [-0.29160059]\n",
      " [ 0.04155404]\n",
      " [ 0.24093035]\n",
      " [ 0.04186059]\n",
      " [-0.29186336]\n",
      " [-0.93529234]\n",
      " [-0.58976593]\n",
      " [ 0.18656583]\n",
      " [ 0.24061333]\n",
      " [-0.03180274]\n",
      " [-0.00312996]\n",
      " [-0.07429995]\n",
      " [-0.01376578]\n",
      " [ 0.30334668]\n",
      " [ 0.05238216]\n",
      " [-0.02575791]\n",
      " [-0.36423244]\n",
      " [ 0.03893627]\n",
      " [-0.11997552]\n",
      " [ 0.30172281]\n",
      " [ 0.12893153]\n",
      " [ 0.25059732]\n",
      " [-0.15500374]\n",
      " [-0.88093103]]\n"
     ]
    }
   ],
   "source": [
    "ppar = ro.r(\"predict(fitmtc)\")\n",
    "print(ppar)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
